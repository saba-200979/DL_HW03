{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hzLUcoprcLr"
   },
   "source": [
    "# part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kxWbATkEreAY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "19a5b7a5ea9c4182bc6fa620a5af6249",
      "ce9da50a38e34b868c18973f0cffc933",
      "bad233a0ed64427cb14c230067600293",
      "3350db4ae2b342d28f5ed16ac05abe2d",
      "f0d1b4af92034aba9cae30b914f1b1f9",
      "aa6dc51798d44580930f20441d04bd16",
      "e9e2206572a14068a167b1d34ef50d52",
      "c02e24ee6888472ab421f3f36e2396af",
      "d22608fe8690420b82ccf121a5583781",
      "44f596b2d8d9451fbd6308f8ea1ce833",
      "d86d5a04a801430d847dc797bfe33acd"
     ]
    },
    "id": "H2mkitGZrmD8",
    "outputId": "4c651634-882e-4a8a-f70e-6f6fc0c71e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_data = transforms.Compose([transforms.Resize(224),transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_data, target_transform = transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y),value=1) ))\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_data)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160,
     "referenced_widgets": [
      "987aa9cc9acb4ca7b5660531fb7c67d6",
      "a27ee97fe2654b3fb4604b2e4069b384",
      "738e1bec978f48e2af3421f4af0fedfa",
      "d9697cae4ad549f4baad0aa935a9245f",
      "0bf51988b82946538e1a85d5b53726fa",
      "99aa764056764b6689c98033b8e6ffd8",
      "463fe3a6f44b4509a4bb9b2b0e0e5dbf",
      "b32d0c88006a488085e46383811fd58b",
      "76da5350fea7462ba25bcbca93ec3391",
      "54a8f3135f1447c0a87409f6927766ac",
      "b8a450688abb424ca6a97be662975900"
     ]
    },
    "id": "QwIuOP8uwcK2",
    "outputId": "9f29c5be-f6ff-40fb-9729-f19a7009d71c"
   },
   "outputs": [],
   "source": [
    "model1=models.resnet50(pretrained=True)\n",
    "\n",
    "for params in model1.parameters():\n",
    "    params.requires_grad=False\n",
    "\n",
    "ftrs=model1.fc.in_features\n",
    "model1.fc=nn.Linear(ftrs, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.to(device)\n",
    "next(model1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BwqvF3ki47_k"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size =16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ljthsBA66Gf0"
   },
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XgTUztQi6Pre"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ublZrcPa6nfQ"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    correct=0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "ImK4vvzS68hN",
    "outputId": "efa4adaf-0bc2-455f-ea39-0a57e82134d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.240924  [    0/50000]\n",
      "loss: 2.226423  [ 1600/50000]\n",
      "loss: 1.974952  [ 3200/50000]\n",
      "loss: 1.808619  [ 4800/50000]\n",
      "loss: 1.892246  [ 6400/50000]\n",
      "loss: 1.603985  [ 8000/50000]\n",
      "loss: 1.652094  [ 9600/50000]\n",
      "loss: 1.543158  [11200/50000]\n",
      "loss: 1.503549  [12800/50000]\n",
      "loss: 1.318970  [14400/50000]\n",
      "loss: 1.406009  [16000/50000]\n",
      "loss: 1.320396  [17600/50000]\n",
      "loss: 1.398761  [19200/50000]\n",
      "loss: 1.251215  [20800/50000]\n",
      "loss: 1.192538  [22400/50000]\n",
      "loss: 1.039668  [24000/50000]\n",
      "loss: 1.413914  [25600/50000]\n",
      "loss: 0.991171  [27200/50000]\n",
      "loss: 1.012909  [28800/50000]\n",
      "loss: 1.116941  [30400/50000]\n",
      "loss: 0.925442  [32000/50000]\n",
      "loss: 1.013851  [33600/50000]\n",
      "loss: 1.061969  [35200/50000]\n",
      "loss: 1.326345  [36800/50000]\n",
      "loss: 1.064024  [38400/50000]\n",
      "loss: 1.306992  [40000/50000]\n",
      "loss: 1.157890  [41600/50000]\n",
      "loss: 1.015867  [43200/50000]\n",
      "loss: 0.959195  [44800/50000]\n",
      "loss: 1.194677  [46400/50000]\n",
      "loss: 1.017253  [48000/50000]\n",
      "loss: 1.071112  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.001163 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.822621  [    0/50000]\n",
      "loss: 0.638555  [ 1600/50000]\n",
      "loss: 0.821701  [ 3200/50000]\n",
      "loss: 0.946079  [ 4800/50000]\n",
      "loss: 0.736167  [ 6400/50000]\n",
      "loss: 0.514036  [ 8000/50000]\n",
      "loss: 0.922640  [ 9600/50000]\n",
      "loss: 0.679307  [11200/50000]\n",
      "loss: 0.624005  [12800/50000]\n",
      "loss: 0.792783  [14400/50000]\n",
      "loss: 1.089941  [16000/50000]\n",
      "loss: 0.903349  [17600/50000]\n",
      "loss: 0.882432  [19200/50000]\n",
      "loss: 1.548894  [20800/50000]\n",
      "loss: 0.703356  [22400/50000]\n",
      "loss: 1.000740  [24000/50000]\n",
      "loss: 0.616621  [25600/50000]\n",
      "loss: 0.753648  [27200/50000]\n",
      "loss: 0.675192  [28800/50000]\n",
      "loss: 1.007884  [30400/50000]\n",
      "loss: 0.875772  [32000/50000]\n",
      "loss: 0.757289  [33600/50000]\n",
      "loss: 0.591308  [35200/50000]\n",
      "loss: 0.809042  [36800/50000]\n",
      "loss: 0.836897  [38400/50000]\n",
      "loss: 0.483852  [40000/50000]\n",
      "loss: 0.517934  [41600/50000]\n",
      "loss: 0.979848  [43200/50000]\n",
      "loss: 0.872750  [44800/50000]\n",
      "loss: 0.765178  [46400/50000]\n",
      "loss: 0.515955  [48000/50000]\n",
      "loss: 0.998391  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.853200 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.730976  [    0/50000]\n",
      "loss: 1.131005  [ 1600/50000]\n",
      "loss: 1.261992  [ 3200/50000]\n",
      "loss: 0.731941  [ 4800/50000]\n",
      "loss: 1.043503  [ 6400/50000]\n",
      "loss: 0.641445  [ 8000/50000]\n",
      "loss: 0.838754  [ 9600/50000]\n",
      "loss: 1.060638  [11200/50000]\n",
      "loss: 1.035628  [12800/50000]\n",
      "loss: 0.736230  [14400/50000]\n",
      "loss: 0.885079  [16000/50000]\n",
      "loss: 0.918621  [17600/50000]\n",
      "loss: 1.277587  [19200/50000]\n",
      "loss: 0.605717  [20800/50000]\n",
      "loss: 0.827126  [22400/50000]\n",
      "loss: 0.665904  [24000/50000]\n",
      "loss: 0.537922  [25600/50000]\n",
      "loss: 0.737555  [27200/50000]\n",
      "loss: 0.576613  [28800/50000]\n",
      "loss: 1.112970  [30400/50000]\n",
      "loss: 1.148827  [32000/50000]\n",
      "loss: 0.799358  [33600/50000]\n",
      "loss: 0.802296  [35200/50000]\n",
      "loss: 0.673042  [36800/50000]\n",
      "loss: 0.811475  [38400/50000]\n",
      "loss: 1.330211  [40000/50000]\n",
      "loss: 0.814974  [41600/50000]\n",
      "loss: 0.816619  [43200/50000]\n",
      "loss: 0.787974  [44800/50000]\n",
      "loss: 0.887534  [46400/50000]\n",
      "loss: 0.672573  [48000/50000]\n",
      "loss: 1.099920  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.786537 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.396806  [    0/50000]\n",
      "loss: 1.044587  [ 1600/50000]\n",
      "loss: 1.042008  [ 3200/50000]\n",
      "loss: 0.796290  [ 4800/50000]\n",
      "loss: 0.574719  [ 6400/50000]\n",
      "loss: 0.626123  [ 8000/50000]\n",
      "loss: 0.761519  [ 9600/50000]\n",
      "loss: 0.760459  [11200/50000]\n",
      "loss: 1.042519  [12800/50000]\n",
      "loss: 0.999988  [14400/50000]\n",
      "loss: 0.521564  [16000/50000]\n",
      "loss: 0.826577  [17600/50000]\n",
      "loss: 0.638320  [19200/50000]\n",
      "loss: 0.890955  [20800/50000]\n",
      "loss: 0.490917  [22400/50000]\n",
      "loss: 1.280999  [24000/50000]\n",
      "loss: 0.763281  [25600/50000]\n",
      "loss: 0.626670  [27200/50000]\n",
      "loss: 0.901344  [28800/50000]\n",
      "loss: 0.554670  [30400/50000]\n",
      "loss: 0.665294  [32000/50000]\n",
      "loss: 0.886538  [33600/50000]\n",
      "loss: 0.410958  [35200/50000]\n",
      "loss: 0.697218  [36800/50000]\n",
      "loss: 0.771925  [38400/50000]\n",
      "loss: 1.040079  [40000/50000]\n",
      "loss: 0.667502  [41600/50000]\n",
      "loss: 0.582762  [43200/50000]\n",
      "loss: 0.801461  [44800/50000]\n",
      "loss: 0.713893  [46400/50000]\n",
      "loss: 0.750598  [48000/50000]\n",
      "loss: 1.087454  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.763458 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.373945  [    0/50000]\n",
      "loss: 0.946431  [ 1600/50000]\n",
      "loss: 0.823101  [ 3200/50000]\n",
      "loss: 0.758999  [ 4800/50000]\n",
      "loss: 0.435884  [ 6400/50000]\n",
      "loss: 0.701352  [ 8000/50000]\n",
      "loss: 0.533702  [ 9600/50000]\n",
      "loss: 0.815863  [11200/50000]\n",
      "loss: 1.256680  [12800/50000]\n",
      "loss: 0.636159  [14400/50000]\n",
      "loss: 0.650216  [16000/50000]\n",
      "loss: 0.952956  [17600/50000]\n",
      "loss: 0.448872  [19200/50000]\n",
      "loss: 0.596736  [20800/50000]\n",
      "loss: 0.650354  [22400/50000]\n",
      "loss: 0.602926  [24000/50000]\n",
      "loss: 0.769494  [25600/50000]\n",
      "loss: 0.651817  [27200/50000]\n",
      "loss: 0.708472  [28800/50000]\n",
      "loss: 0.782189  [30400/50000]\n",
      "loss: 0.443970  [32000/50000]\n",
      "loss: 0.613134  [33600/50000]\n",
      "loss: 0.956816  [35200/50000]\n",
      "loss: 0.474648  [36800/50000]\n",
      "loss: 0.847491  [38400/50000]\n",
      "loss: 1.025562  [40000/50000]\n",
      "loss: 0.914134  [41600/50000]\n",
      "loss: 0.595892  [43200/50000]\n",
      "loss: 0.601097  [44800/50000]\n",
      "loss: 0.747024  [46400/50000]\n",
      "loss: 0.629695  [48000/50000]\n",
      "loss: 0.341226  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.734399 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.949090  [    0/50000]\n",
      "loss: 0.858928  [ 1600/50000]\n",
      "loss: 0.925022  [ 3200/50000]\n",
      "loss: 1.058383  [ 4800/50000]\n",
      "loss: 0.652625  [ 6400/50000]\n",
      "loss: 0.400096  [ 8000/50000]\n",
      "loss: 0.621504  [ 9600/50000]\n",
      "loss: 0.765425  [11200/50000]\n",
      "loss: 0.679944  [12800/50000]\n",
      "loss: 0.740619  [14400/50000]\n",
      "loss: 0.636133  [16000/50000]\n",
      "loss: 0.552897  [17600/50000]\n",
      "loss: 0.722242  [19200/50000]\n",
      "loss: 0.948845  [20800/50000]\n",
      "loss: 1.049778  [22400/50000]\n",
      "loss: 0.821118  [24000/50000]\n",
      "loss: 0.512435  [25600/50000]\n",
      "loss: 0.801452  [27200/50000]\n",
      "loss: 0.913871  [28800/50000]\n",
      "loss: 0.639504  [30400/50000]\n",
      "loss: 0.936947  [32000/50000]\n",
      "loss: 0.814172  [33600/50000]\n",
      "loss: 0.791130  [35200/50000]\n",
      "loss: 0.818877  [36800/50000]\n",
      "loss: 0.557594  [38400/50000]\n",
      "loss: 0.875748  [40000/50000]\n",
      "loss: 0.613050  [41600/50000]\n",
      "loss: 0.841439  [43200/50000]\n",
      "loss: 0.578929  [44800/50000]\n",
      "loss: 0.471019  [46400/50000]\n",
      "loss: 0.941426  [48000/50000]\n",
      "loss: 0.993922  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.719962 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.808026  [    0/50000]\n",
      "loss: 0.554057  [ 1600/50000]\n",
      "loss: 0.597200  [ 3200/50000]\n",
      "loss: 0.710563  [ 4800/50000]\n",
      "loss: 0.469977  [ 6400/50000]\n",
      "loss: 0.846236  [ 8000/50000]\n",
      "loss: 0.815523  [ 9600/50000]\n",
      "loss: 0.601717  [11200/50000]\n",
      "loss: 0.751246  [12800/50000]\n",
      "loss: 0.629728  [14400/50000]\n",
      "loss: 0.413606  [16000/50000]\n",
      "loss: 0.780380  [17600/50000]\n",
      "loss: 0.460217  [19200/50000]\n",
      "loss: 0.438340  [20800/50000]\n",
      "loss: 0.775725  [22400/50000]\n",
      "loss: 0.717517  [24000/50000]\n",
      "loss: 0.423176  [25600/50000]\n",
      "loss: 0.656286  [27200/50000]\n",
      "loss: 0.706649  [28800/50000]\n",
      "loss: 0.546031  [30400/50000]\n",
      "loss: 0.787551  [32000/50000]\n",
      "loss: 0.497592  [33600/50000]\n",
      "loss: 0.469055  [35200/50000]\n",
      "loss: 0.923145  [36800/50000]\n",
      "loss: 0.440480  [38400/50000]\n",
      "loss: 0.688707  [40000/50000]\n",
      "loss: 0.904486  [41600/50000]\n",
      "loss: 1.087549  [43200/50000]\n",
      "loss: 0.760296  [44800/50000]\n",
      "loss: 0.578676  [46400/50000]\n",
      "loss: 0.487736  [48000/50000]\n",
      "loss: 0.548678  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.703915 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.376929  [    0/50000]\n",
      "loss: 0.654210  [ 1600/50000]\n",
      "loss: 0.790679  [ 3200/50000]\n",
      "loss: 0.585897  [ 4800/50000]\n",
      "loss: 0.987538  [ 6400/50000]\n",
      "loss: 0.554752  [ 8000/50000]\n",
      "loss: 0.776501  [ 9600/50000]\n",
      "loss: 0.742959  [11200/50000]\n",
      "loss: 0.737357  [12800/50000]\n",
      "loss: 0.483582  [14400/50000]\n",
      "loss: 0.539052  [16000/50000]\n",
      "loss: 0.942881  [17600/50000]\n",
      "loss: 0.605996  [19200/50000]\n",
      "loss: 0.649079  [20800/50000]\n",
      "loss: 0.527403  [22400/50000]\n",
      "loss: 0.739621  [24000/50000]\n",
      "loss: 0.991478  [25600/50000]\n",
      "loss: 0.726068  [27200/50000]\n",
      "loss: 0.378284  [28800/50000]\n",
      "loss: 0.850237  [30400/50000]\n",
      "loss: 0.848498  [32000/50000]\n",
      "loss: 0.336941  [33600/50000]\n",
      "loss: 0.358658  [35200/50000]\n",
      "loss: 0.811491  [36800/50000]\n",
      "loss: 0.628899  [38400/50000]\n",
      "loss: 0.276841  [40000/50000]\n",
      "loss: 0.364787  [41600/50000]\n",
      "loss: 0.822509  [43200/50000]\n",
      "loss: 0.991247  [44800/50000]\n",
      "loss: 0.856317  [46400/50000]\n",
      "loss: 0.740269  [48000/50000]\n",
      "loss: 1.118500  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.697902 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.070298  [    0/50000]\n",
      "loss: 0.574294  [ 1600/50000]\n",
      "loss: 0.697311  [ 3200/50000]\n",
      "loss: 0.575686  [ 4800/50000]\n",
      "loss: 0.544963  [ 6400/50000]\n",
      "loss: 0.826077  [ 8000/50000]\n",
      "loss: 0.939788  [ 9600/50000]\n",
      "loss: 0.609373  [11200/50000]\n",
      "loss: 0.617379  [12800/50000]\n",
      "loss: 0.373373  [14400/50000]\n",
      "loss: 0.535347  [16000/50000]\n",
      "loss: 0.805150  [17600/50000]\n",
      "loss: 0.901002  [19200/50000]\n",
      "loss: 0.395839  [20800/50000]\n",
      "loss: 0.611942  [22400/50000]\n",
      "loss: 0.955111  [24000/50000]\n",
      "loss: 0.632911  [25600/50000]\n",
      "loss: 0.612020  [27200/50000]\n",
      "loss: 0.429606  [28800/50000]\n",
      "loss: 0.802357  [30400/50000]\n",
      "loss: 0.564582  [32000/50000]\n",
      "loss: 0.825645  [33600/50000]\n",
      "loss: 0.689177  [35200/50000]\n",
      "loss: 0.636264  [36800/50000]\n",
      "loss: 0.623194  [38400/50000]\n",
      "loss: 0.560845  [40000/50000]\n",
      "loss: 0.651024  [41600/50000]\n",
      "loss: 0.603217  [43200/50000]\n",
      "loss: 0.290890  [44800/50000]\n",
      "loss: 0.827759  [46400/50000]\n",
      "loss: 0.916944  [48000/50000]\n",
      "loss: 1.046461  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.692388 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.363525  [    0/50000]\n",
      "loss: 0.605315  [ 1600/50000]\n",
      "loss: 0.482776  [ 3200/50000]\n",
      "loss: 0.842895  [ 4800/50000]\n",
      "loss: 1.012385  [ 6400/50000]\n",
      "loss: 0.926462  [ 8000/50000]\n",
      "loss: 0.842552  [ 9600/50000]\n",
      "loss: 0.321346  [11200/50000]\n",
      "loss: 0.605078  [12800/50000]\n",
      "loss: 0.987212  [14400/50000]\n",
      "loss: 0.583755  [16000/50000]\n",
      "loss: 0.245392  [17600/50000]\n",
      "loss: 1.124289  [19200/50000]\n",
      "loss: 0.706278  [20800/50000]\n",
      "loss: 0.535764  [22400/50000]\n",
      "loss: 0.405293  [24000/50000]\n",
      "loss: 0.894274  [25600/50000]\n",
      "loss: 0.716290  [27200/50000]\n",
      "loss: 0.486116  [28800/50000]\n",
      "loss: 0.706764  [30400/50000]\n",
      "loss: 0.611343  [32000/50000]\n",
      "loss: 0.666814  [33600/50000]\n",
      "loss: 0.790549  [35200/50000]\n",
      "loss: 0.986580  [36800/50000]\n",
      "loss: 0.611481  [38400/50000]\n",
      "loss: 0.909605  [40000/50000]\n",
      "loss: 0.706430  [41600/50000]\n",
      "loss: 0.485553  [43200/50000]\n",
      "loss: 0.470996  [44800/50000]\n",
      "loss: 0.937467  [46400/50000]\n",
      "loss: 0.539696  [48000/50000]\n",
      "loss: 0.294081  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.682404 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model1, loss_fn, optimizer)\n",
    "    test_loop(testloader, model1, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1, 'p2_model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kQ_rm3A7GrN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader4 = DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "testloader4 = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=models.resnet18(pretrained=False)\n",
    "ftrs=model2.fc.in_features\n",
    "model2.fc=nn.Linear(ftrs, 10)\n",
    "\n",
    "model2.to(device)\n",
    "next(model2.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load('p2_model1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size =16\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def newloss(predicted, targets, teacher_target, tau, alpha):\n",
    "    s1 = F.softmax(predicted, dim=1)\n",
    "    t = F.softmax(teacher_target/tau, dim=1)\n",
    "    s2= F.softmax(predicted/tau, dim=1)\n",
    "    soft_loss = alpha * tau * tau * F.cross_entropy(t, s2)\n",
    "    hard_loss = (1-alpha) * F.cross_entropy(targets, s1)\n",
    "    loss = soft_loss + hard_loss \n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, smodel, tmodel, loss_fn, optimizer, tau, alpha):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        pred = smodel(X)\n",
    "        t_target=tmodel(X)\n",
    "        \n",
    "        loss = newloss(pred, y, t_target, tau, alpha)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "           \n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.987925  [    0/50000]\n",
      "loss: 4.606635  [ 1600/50000]\n",
      "loss: 4.711490  [ 3200/50000]\n",
      "loss: 4.990084  [ 4800/50000]\n",
      "loss: 5.040056  [ 6400/50000]\n",
      "loss: 4.876433  [ 8000/50000]\n",
      "loss: 4.547595  [ 9600/50000]\n",
      "loss: 4.678495  [11200/50000]\n",
      "loss: 4.708873  [12800/50000]\n",
      "loss: 4.975726  [14400/50000]\n",
      "loss: 5.098983  [16000/50000]\n",
      "loss: 4.645491  [17600/50000]\n",
      "loss: 4.794865  [19200/50000]\n",
      "loss: 4.736393  [20800/50000]\n",
      "loss: 4.850601  [22400/50000]\n",
      "loss: 4.844409  [24000/50000]\n",
      "loss: 4.835175  [25600/50000]\n",
      "loss: 4.730545  [27200/50000]\n",
      "loss: 4.743885  [28800/50000]\n",
      "loss: 4.791839  [30400/50000]\n",
      "loss: 4.705799  [32000/50000]\n",
      "loss: 4.804523  [33600/50000]\n",
      "loss: 5.015117  [35200/50000]\n",
      "loss: 4.551866  [36800/50000]\n",
      "loss: 4.949496  [38400/50000]\n",
      "loss: 4.649533  [40000/50000]\n",
      "loss: 4.928356  [41600/50000]\n",
      "loss: 4.998233  [43200/50000]\n",
      "loss: 4.839613  [44800/50000]\n",
      "loss: 4.704820  [46400/50000]\n",
      "loss: 4.884536  [48000/50000]\n",
      "loss: 4.494431  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 31.4%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 5.044665  [    0/50000]\n",
      "loss: 4.908400  [ 1600/50000]\n",
      "loss: 4.685875  [ 3200/50000]\n",
      "loss: 4.884126  [ 4800/50000]\n",
      "loss: 4.761588  [ 6400/50000]\n",
      "loss: 4.823020  [ 8000/50000]\n",
      "loss: 4.880056  [ 9600/50000]\n",
      "loss: 4.807154  [11200/50000]\n",
      "loss: 4.721915  [12800/50000]\n",
      "loss: 4.562572  [14400/50000]\n",
      "loss: 4.428937  [16000/50000]\n",
      "loss: 4.867303  [17600/50000]\n",
      "loss: 4.935466  [19200/50000]\n",
      "loss: 4.498528  [20800/50000]\n",
      "loss: 4.689978  [22400/50000]\n",
      "loss: 4.789913  [24000/50000]\n",
      "loss: 4.785386  [25600/50000]\n",
      "loss: 4.876288  [27200/50000]\n",
      "loss: 4.735047  [28800/50000]\n",
      "loss: 4.540298  [30400/50000]\n",
      "loss: 4.927707  [32000/50000]\n",
      "loss: 4.725797  [33600/50000]\n",
      "loss: 4.766792  [35200/50000]\n",
      "loss: 4.716426  [36800/50000]\n",
      "loss: 4.546815  [38400/50000]\n",
      "loss: 4.464660  [40000/50000]\n",
      "loss: 4.828668  [41600/50000]\n",
      "loss: 4.861320  [43200/50000]\n",
      "loss: 4.770020  [44800/50000]\n",
      "loss: 4.868064  [46400/50000]\n",
      "loss: 4.361256  [48000/50000]\n",
      "loss: 4.886621  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.637815  [    0/50000]\n",
      "loss: 4.529849  [ 1600/50000]\n",
      "loss: 4.538522  [ 3200/50000]\n",
      "loss: 4.671524  [ 4800/50000]\n",
      "loss: 4.626104  [ 6400/50000]\n",
      "loss: 4.426656  [ 8000/50000]\n",
      "loss: 4.526483  [ 9600/50000]\n",
      "loss: 4.806590  [11200/50000]\n",
      "loss: 4.685874  [12800/50000]\n",
      "loss: 4.721651  [14400/50000]\n",
      "loss: 4.675049  [16000/50000]\n",
      "loss: 4.403547  [17600/50000]\n",
      "loss: 4.659517  [19200/50000]\n",
      "loss: 4.378144  [20800/50000]\n",
      "loss: 4.691135  [22400/50000]\n",
      "loss: 4.757103  [24000/50000]\n",
      "loss: 4.820354  [25600/50000]\n",
      "loss: 4.659312  [27200/50000]\n",
      "loss: 4.796562  [28800/50000]\n",
      "loss: 4.425442  [30400/50000]\n",
      "loss: 4.547847  [32000/50000]\n",
      "loss: 4.744428  [33600/50000]\n",
      "loss: 4.305328  [35200/50000]\n",
      "loss: 4.712454  [36800/50000]\n",
      "loss: 4.613319  [38400/50000]\n",
      "loss: 4.651440  [40000/50000]\n",
      "loss: 4.661101  [41600/50000]\n",
      "loss: 4.676097  [43200/50000]\n",
      "loss: 4.700818  [44800/50000]\n",
      "loss: 4.216925  [46400/50000]\n",
      "loss: 4.528337  [48000/50000]\n",
      "loss: 4.510950  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.455017  [    0/50000]\n",
      "loss: 4.835541  [ 1600/50000]\n",
      "loss: 4.516648  [ 3200/50000]\n",
      "loss: 4.661186  [ 4800/50000]\n",
      "loss: 4.518123  [ 6400/50000]\n",
      "loss: 4.800003  [ 8000/50000]\n",
      "loss: 4.689437  [ 9600/50000]\n",
      "loss: 4.736045  [11200/50000]\n",
      "loss: 4.520490  [12800/50000]\n",
      "loss: 4.456754  [14400/50000]\n",
      "loss: 4.479845  [16000/50000]\n",
      "loss: 4.788862  [17600/50000]\n",
      "loss: 4.531905  [19200/50000]\n",
      "loss: 4.389368  [20800/50000]\n",
      "loss: 4.587492  [22400/50000]\n",
      "loss: 4.537761  [24000/50000]\n",
      "loss: 4.216904  [25600/50000]\n",
      "loss: 5.095579  [27200/50000]\n",
      "loss: 4.520030  [28800/50000]\n",
      "loss: 4.534940  [30400/50000]\n",
      "loss: 4.409478  [32000/50000]\n",
      "loss: 4.608364  [33600/50000]\n",
      "loss: 4.591140  [35200/50000]\n",
      "loss: 4.526519  [36800/50000]\n",
      "loss: 4.632976  [38400/50000]\n",
      "loss: 4.815894  [40000/50000]\n",
      "loss: 4.604556  [41600/50000]\n",
      "loss: 4.473306  [43200/50000]\n",
      "loss: 4.711115  [44800/50000]\n",
      "loss: 4.746672  [46400/50000]\n",
      "loss: 4.447494  [48000/50000]\n",
      "loss: 4.494713  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.377616  [    0/50000]\n",
      "loss: 4.562676  [ 1600/50000]\n",
      "loss: 4.614365  [ 3200/50000]\n",
      "loss: 4.740880  [ 4800/50000]\n",
      "loss: 4.758744  [ 6400/50000]\n",
      "loss: 4.511378  [ 8000/50000]\n",
      "loss: 4.240865  [ 9600/50000]\n",
      "loss: 4.631720  [11200/50000]\n",
      "loss: 4.424912  [12800/50000]\n",
      "loss: 4.320116  [14400/50000]\n",
      "loss: 4.513904  [16000/50000]\n",
      "loss: 4.452093  [17600/50000]\n",
      "loss: 4.768148  [19200/50000]\n",
      "loss: 4.336896  [20800/50000]\n",
      "loss: 4.748821  [22400/50000]\n",
      "loss: 4.349924  [24000/50000]\n",
      "loss: 4.446587  [25600/50000]\n",
      "loss: 4.525908  [27200/50000]\n",
      "loss: 4.424116  [28800/50000]\n",
      "loss: 4.654159  [30400/50000]\n",
      "loss: 4.378185  [32000/50000]\n",
      "loss: 4.822986  [33600/50000]\n",
      "loss: 4.184962  [35200/50000]\n",
      "loss: 4.689572  [36800/50000]\n",
      "loss: 4.426519  [38400/50000]\n",
      "loss: 4.376614  [40000/50000]\n",
      "loss: 4.274634  [41600/50000]\n",
      "loss: 4.550668  [43200/50000]\n",
      "loss: 4.023983  [44800/50000]\n",
      "loss: 4.628041  [46400/50000]\n",
      "loss: 4.403030  [48000/50000]\n",
      "loss: 4.309788  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.384925  [    0/50000]\n",
      "loss: 4.386889  [ 1600/50000]\n",
      "loss: 4.531502  [ 3200/50000]\n",
      "loss: 4.498803  [ 4800/50000]\n",
      "loss: 4.281681  [ 6400/50000]\n",
      "loss: 4.473247  [ 8000/50000]\n",
      "loss: 4.472006  [ 9600/50000]\n",
      "loss: 4.424046  [11200/50000]\n",
      "loss: 4.515479  [12800/50000]\n",
      "loss: 4.637485  [14400/50000]\n",
      "loss: 4.299838  [16000/50000]\n",
      "loss: 4.673203  [17600/50000]\n",
      "loss: 4.300185  [19200/50000]\n",
      "loss: 4.744913  [20800/50000]\n",
      "loss: 4.382586  [22400/50000]\n",
      "loss: 4.624620  [24000/50000]\n",
      "loss: 4.268299  [25600/50000]\n",
      "loss: 4.735422  [27200/50000]\n",
      "loss: 4.244615  [28800/50000]\n",
      "loss: 4.382530  [30400/50000]\n",
      "loss: 4.731524  [32000/50000]\n",
      "loss: 4.682664  [33600/50000]\n",
      "loss: 4.452540  [35200/50000]\n",
      "loss: 4.458185  [36800/50000]\n",
      "loss: 4.188201  [38400/50000]\n",
      "loss: 4.249030  [40000/50000]\n",
      "loss: 4.772471  [41600/50000]\n",
      "loss: 4.406294  [43200/50000]\n",
      "loss: 4.408299  [44800/50000]\n",
      "loss: 4.657089  [46400/50000]\n",
      "loss: 4.440615  [48000/50000]\n",
      "loss: 4.445849  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4.555922  [    0/50000]\n",
      "loss: 4.238768  [ 1600/50000]\n",
      "loss: 4.446683  [ 3200/50000]\n",
      "loss: 4.646316  [ 4800/50000]\n",
      "loss: 4.544820  [ 6400/50000]\n",
      "loss: 4.547822  [ 8000/50000]\n",
      "loss: 4.230009  [ 9600/50000]\n",
      "loss: 4.488861  [11200/50000]\n",
      "loss: 4.367850  [12800/50000]\n",
      "loss: 4.329696  [14400/50000]\n",
      "loss: 4.458105  [16000/50000]\n",
      "loss: 4.392839  [17600/50000]\n",
      "loss: 4.535470  [19200/50000]\n",
      "loss: 4.493177  [20800/50000]\n",
      "loss: 4.556841  [22400/50000]\n",
      "loss: 4.621512  [24000/50000]\n",
      "loss: 4.438472  [25600/50000]\n",
      "loss: 4.330214  [27200/50000]\n",
      "loss: 4.471447  [28800/50000]\n",
      "loss: 4.481806  [30400/50000]\n",
      "loss: 4.592994  [32000/50000]\n",
      "loss: 4.209595  [33600/50000]\n",
      "loss: 4.559875  [35200/50000]\n",
      "loss: 4.450400  [36800/50000]\n",
      "loss: 4.372076  [38400/50000]\n",
      "loss: 4.615146  [40000/50000]\n",
      "loss: 4.574856  [41600/50000]\n",
      "loss: 4.200927  [43200/50000]\n",
      "loss: 4.113509  [44800/50000]\n",
      "loss: 4.582881  [46400/50000]\n",
      "loss: 4.606466  [48000/50000]\n",
      "loss: 4.192369  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4.245365  [    0/50000]\n",
      "loss: 4.624438  [ 1600/50000]\n",
      "loss: 4.262760  [ 3200/50000]\n",
      "loss: 4.076826  [ 4800/50000]\n",
      "loss: 4.186023  [ 6400/50000]\n",
      "loss: 4.210804  [ 8000/50000]\n",
      "loss: 4.401693  [ 9600/50000]\n",
      "loss: 4.252068  [11200/50000]\n",
      "loss: 4.584203  [12800/50000]\n",
      "loss: 4.272104  [14400/50000]\n",
      "loss: 4.389169  [16000/50000]\n",
      "loss: 4.442129  [17600/50000]\n",
      "loss: 4.264693  [19200/50000]\n",
      "loss: 4.319695  [20800/50000]\n",
      "loss: 4.579090  [22400/50000]\n",
      "loss: 4.347142  [24000/50000]\n",
      "loss: 4.400788  [25600/50000]\n",
      "loss: 4.606819  [27200/50000]\n",
      "loss: 4.212273  [28800/50000]\n",
      "loss: 4.196776  [30400/50000]\n",
      "loss: 4.355055  [32000/50000]\n",
      "loss: 4.575398  [33600/50000]\n",
      "loss: 4.331681  [35200/50000]\n",
      "loss: 4.285819  [36800/50000]\n",
      "loss: 4.089210  [38400/50000]\n",
      "loss: 4.360409  [40000/50000]\n",
      "loss: 4.225981  [41600/50000]\n",
      "loss: 4.461575  [43200/50000]\n",
      "loss: 4.194970  [44800/50000]\n",
      "loss: 4.318084  [46400/50000]\n",
      "loss: 4.160426  [48000/50000]\n",
      "loss: 4.322417  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 4.446448  [    0/50000]\n",
      "loss: 4.517345  [ 1600/50000]\n",
      "loss: 4.046323  [ 3200/50000]\n",
      "loss: 4.373162  [ 4800/50000]\n",
      "loss: 4.448200  [ 6400/50000]\n",
      "loss: 4.197838  [ 8000/50000]\n",
      "loss: 4.493294  [ 9600/50000]\n",
      "loss: 4.282422  [11200/50000]\n",
      "loss: 4.350380  [12800/50000]\n",
      "loss: 4.316170  [14400/50000]\n",
      "loss: 4.361224  [16000/50000]\n",
      "loss: 4.451129  [17600/50000]\n",
      "loss: 4.215435  [19200/50000]\n",
      "loss: 4.442079  [20800/50000]\n",
      "loss: 4.521091  [22400/50000]\n",
      "loss: 4.468412  [24000/50000]\n",
      "loss: 4.303137  [25600/50000]\n",
      "loss: 4.367311  [27200/50000]\n",
      "loss: 4.439724  [28800/50000]\n",
      "loss: 4.280211  [30400/50000]\n",
      "loss: 4.141847  [32000/50000]\n",
      "loss: 4.362917  [33600/50000]\n",
      "loss: 4.409606  [35200/50000]\n",
      "loss: 4.295208  [36800/50000]\n",
      "loss: 4.189964  [38400/50000]\n",
      "loss: 4.378926  [40000/50000]\n",
      "loss: 4.321293  [41600/50000]\n",
      "loss: 4.220027  [43200/50000]\n",
      "loss: 4.083039  [44800/50000]\n",
      "loss: 4.067755  [46400/50000]\n",
      "loss: 4.355035  [48000/50000]\n",
      "loss: 4.145585  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 4.307904  [    0/50000]\n",
      "loss: 4.308311  [ 1600/50000]\n",
      "loss: 4.409587  [ 3200/50000]\n",
      "loss: 4.486690  [ 4800/50000]\n",
      "loss: 4.306970  [ 6400/50000]\n",
      "loss: 4.307657  [ 8000/50000]\n",
      "loss: 4.012905  [ 9600/50000]\n",
      "loss: 4.247054  [11200/50000]\n",
      "loss: 3.993012  [12800/50000]\n",
      "loss: 4.146653  [14400/50000]\n",
      "loss: 4.282493  [16000/50000]\n",
      "loss: 4.603240  [17600/50000]\n",
      "loss: 4.115112  [19200/50000]\n",
      "loss: 4.217549  [20800/50000]\n",
      "loss: 4.227656  [22400/50000]\n",
      "loss: 4.176418  [24000/50000]\n",
      "loss: 4.517358  [25600/50000]\n",
      "loss: 4.243970  [27200/50000]\n",
      "loss: 4.264222  [28800/50000]\n",
      "loss: 4.414284  [30400/50000]\n",
      "loss: 4.255709  [32000/50000]\n",
      "loss: 4.148968  [33600/50000]\n",
      "loss: 4.194893  [35200/50000]\n",
      "loss: 4.466705  [36800/50000]\n",
      "loss: 4.322238  [38400/50000]\n",
      "loss: 4.059229  [40000/50000]\n",
      "loss: 4.298804  [41600/50000]\n",
      "loss: 4.220056  [43200/50000]\n",
      "loss: 4.243743  [44800/50000]\n",
      "loss: 4.279790  [46400/50000]\n",
      "loss: 4.336408  [48000/50000]\n",
      "loss: 4.319832  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4.390119  [    0/50000]\n",
      "loss: 4.417847  [ 1600/50000]\n",
      "loss: 4.504602  [ 3200/50000]\n",
      "loss: 4.353541  [ 4800/50000]\n",
      "loss: 4.255149  [ 6400/50000]\n",
      "loss: 4.244317  [ 8000/50000]\n",
      "loss: 4.087669  [ 9600/50000]\n",
      "loss: 4.521804  [11200/50000]\n",
      "loss: 4.294202  [12800/50000]\n",
      "loss: 4.200945  [14400/50000]\n",
      "loss: 4.085644  [16000/50000]\n",
      "loss: 4.245335  [17600/50000]\n",
      "loss: 4.085510  [19200/50000]\n",
      "loss: 4.313913  [20800/50000]\n",
      "loss: 4.181694  [22400/50000]\n",
      "loss: 4.485848  [24000/50000]\n",
      "loss: 4.519533  [25600/50000]\n",
      "loss: 4.207117  [27200/50000]\n",
      "loss: 4.048130  [28800/50000]\n",
      "loss: 4.397873  [30400/50000]\n",
      "loss: 4.298462  [32000/50000]\n",
      "loss: 4.400566  [33600/50000]\n",
      "loss: 4.266606  [35200/50000]\n",
      "loss: 4.427647  [36800/50000]\n",
      "loss: 4.471418  [38400/50000]\n",
      "loss: 3.923303  [40000/50000]\n",
      "loss: 4.088748  [41600/50000]\n",
      "loss: 4.271277  [43200/50000]\n",
      "loss: 4.405013  [44800/50000]\n",
      "loss: 4.423265  [46400/50000]\n",
      "loss: 4.150700  [48000/50000]\n",
      "loss: 4.431850  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 4.408267  [    0/50000]\n",
      "loss: 4.092514  [ 1600/50000]\n",
      "loss: 4.216372  [ 3200/50000]\n",
      "loss: 4.139074  [ 4800/50000]\n",
      "loss: 4.321237  [ 6400/50000]\n",
      "loss: 4.234592  [ 8000/50000]\n",
      "loss: 4.089840  [ 9600/50000]\n",
      "loss: 3.953527  [11200/50000]\n",
      "loss: 4.185343  [12800/50000]\n",
      "loss: 4.212405  [14400/50000]\n",
      "loss: 4.265992  [16000/50000]\n",
      "loss: 4.112793  [17600/50000]\n",
      "loss: 3.912214  [19200/50000]\n",
      "loss: 4.161948  [20800/50000]\n",
      "loss: 4.317620  [22400/50000]\n",
      "loss: 4.312366  [24000/50000]\n",
      "loss: 4.345000  [25600/50000]\n",
      "loss: 4.078324  [27200/50000]\n",
      "loss: 4.325553  [28800/50000]\n",
      "loss: 4.122541  [30400/50000]\n",
      "loss: 4.232066  [32000/50000]\n",
      "loss: 4.577312  [33600/50000]\n",
      "loss: 4.446534  [35200/50000]\n",
      "loss: 4.296072  [36800/50000]\n",
      "loss: 4.434941  [38400/50000]\n",
      "loss: 4.089645  [40000/50000]\n",
      "loss: 4.108740  [41600/50000]\n",
      "loss: 4.278549  [43200/50000]\n",
      "loss: 4.270718  [44800/50000]\n",
      "loss: 4.066596  [46400/50000]\n",
      "loss: 4.339271  [48000/50000]\n",
      "loss: 4.104894  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 4.095952  [    0/50000]\n",
      "loss: 4.320702  [ 1600/50000]\n",
      "loss: 4.181736  [ 3200/50000]\n",
      "loss: 4.559016  [ 4800/50000]\n",
      "loss: 4.295489  [ 6400/50000]\n",
      "loss: 4.164896  [ 8000/50000]\n",
      "loss: 4.346084  [ 9600/50000]\n",
      "loss: 4.240211  [11200/50000]\n",
      "loss: 4.522455  [12800/50000]\n",
      "loss: 3.928766  [14400/50000]\n",
      "loss: 4.105660  [16000/50000]\n",
      "loss: 3.964422  [17600/50000]\n",
      "loss: 4.317704  [19200/50000]\n",
      "loss: 3.987675  [20800/50000]\n",
      "loss: 4.320599  [22400/50000]\n",
      "loss: 4.444336  [24000/50000]\n",
      "loss: 4.443015  [25600/50000]\n",
      "loss: 4.177879  [27200/50000]\n",
      "loss: 4.219625  [28800/50000]\n",
      "loss: 4.334617  [30400/50000]\n",
      "loss: 4.036025  [32000/50000]\n",
      "loss: 4.138466  [33600/50000]\n",
      "loss: 4.249754  [35200/50000]\n",
      "loss: 4.372786  [36800/50000]\n",
      "loss: 4.485576  [38400/50000]\n",
      "loss: 4.318198  [40000/50000]\n",
      "loss: 4.237230  [41600/50000]\n",
      "loss: 4.272088  [43200/50000]\n",
      "loss: 4.327637  [44800/50000]\n",
      "loss: 4.014638  [46400/50000]\n",
      "loss: 3.962801  [48000/50000]\n",
      "loss: 4.254796  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 4.489227  [    0/50000]\n",
      "loss: 4.274246  [ 1600/50000]\n",
      "loss: 4.460938  [ 3200/50000]\n",
      "loss: 4.098709  [ 4800/50000]\n",
      "loss: 4.350398  [ 6400/50000]\n",
      "loss: 3.858740  [ 8000/50000]\n",
      "loss: 4.080464  [ 9600/50000]\n",
      "loss: 4.264470  [11200/50000]\n",
      "loss: 3.963228  [12800/50000]\n",
      "loss: 4.209699  [14400/50000]\n",
      "loss: 4.147003  [16000/50000]\n",
      "loss: 4.068650  [17600/50000]\n",
      "loss: 4.077169  [19200/50000]\n",
      "loss: 4.265693  [20800/50000]\n",
      "loss: 4.478193  [22400/50000]\n",
      "loss: 4.266596  [24000/50000]\n",
      "loss: 4.216179  [25600/50000]\n",
      "loss: 3.927327  [27200/50000]\n",
      "loss: 4.306124  [28800/50000]\n",
      "loss: 4.101905  [30400/50000]\n",
      "loss: 4.189514  [32000/50000]\n",
      "loss: 4.207650  [33600/50000]\n",
      "loss: 4.275627  [35200/50000]\n",
      "loss: 4.250711  [36800/50000]\n",
      "loss: 4.286390  [38400/50000]\n",
      "loss: 4.311673  [40000/50000]\n",
      "loss: 4.155611  [41600/50000]\n",
      "loss: 4.310203  [43200/50000]\n",
      "loss: 4.048713  [44800/50000]\n",
      "loss: 4.085683  [46400/50000]\n",
      "loss: 4.439075  [48000/50000]\n",
      "loss: 4.237463  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 4.182690  [    0/50000]\n",
      "loss: 4.238742  [ 1600/50000]\n",
      "loss: 4.314252  [ 3200/50000]\n",
      "loss: 4.291530  [ 4800/50000]\n",
      "loss: 4.380095  [ 6400/50000]\n",
      "loss: 4.262053  [ 8000/50000]\n",
      "loss: 4.280130  [ 9600/50000]\n",
      "loss: 4.150146  [11200/50000]\n",
      "loss: 4.142601  [12800/50000]\n",
      "loss: 4.329125  [14400/50000]\n",
      "loss: 4.165905  [16000/50000]\n",
      "loss: 4.339842  [17600/50000]\n",
      "loss: 4.220775  [19200/50000]\n",
      "loss: 4.126639  [20800/50000]\n",
      "loss: 4.212142  [22400/50000]\n",
      "loss: 4.196322  [24000/50000]\n",
      "loss: 4.434088  [25600/50000]\n",
      "loss: 4.099028  [27200/50000]\n",
      "loss: 4.145182  [28800/50000]\n",
      "loss: 4.331754  [30400/50000]\n",
      "loss: 4.361812  [32000/50000]\n",
      "loss: 4.059785  [33600/50000]\n",
      "loss: 3.918078  [35200/50000]\n",
      "loss: 4.166899  [36800/50000]\n",
      "loss: 4.344259  [38400/50000]\n",
      "loss: 4.266242  [40000/50000]\n",
      "loss: 4.084584  [41600/50000]\n",
      "loss: 4.312578  [43200/50000]\n",
      "loss: 4.158566  [44800/50000]\n",
      "loss: 4.184652  [46400/50000]\n",
      "loss: 4.329169  [48000/50000]\n",
      "loss: 4.334101  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.000000 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tau=2\n",
    "alpha=0.4\n",
    "ls_fn=nn.CrossEntropyLoss()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader4, model2, model1, newloss, optimizer, tau, alpha)\n",
    "    test_loop(testloader4, model2, ls_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2, 'p2_model2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher accuracies can be achieved by training in more epochs, but because it takes several hours, just 15 epochs is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader5 = DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "testloader5 = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model3=models.resnet18(pretrained=False)\n",
    "\n",
    "ftrs=model3.fc.in_features\n",
    "model3.fc=nn.Linear(ftrs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.to(device)\n",
    "next(model3.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size =16\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model3.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.896867  [    0/50000]\n",
      "loss: 2.226656  [ 1600/50000]\n",
      "loss: 1.574036  [ 3200/50000]\n",
      "loss: 1.675238  [ 4800/50000]\n",
      "loss: 1.926916  [ 6400/50000]\n",
      "loss: 1.811888  [ 8000/50000]\n",
      "loss: 1.530740  [ 9600/50000]\n",
      "loss: 1.541551  [11200/50000]\n",
      "loss: 1.801526  [12800/50000]\n",
      "loss: 1.494005  [14400/50000]\n",
      "loss: 1.756647  [16000/50000]\n",
      "loss: 1.653669  [17600/50000]\n",
      "loss: 1.270565  [19200/50000]\n",
      "loss: 1.515260  [20800/50000]\n",
      "loss: 1.416307  [22400/50000]\n",
      "loss: 1.088918  [24000/50000]\n",
      "loss: 0.874840  [25600/50000]\n",
      "loss: 1.032787  [27200/50000]\n",
      "loss: 1.201496  [28800/50000]\n",
      "loss: 0.985781  [30400/50000]\n",
      "loss: 1.264638  [32000/50000]\n",
      "loss: 1.202904  [33600/50000]\n",
      "loss: 1.396457  [35200/50000]\n",
      "loss: 0.936910  [36800/50000]\n",
      "loss: 1.212113  [38400/50000]\n",
      "loss: 0.853512  [40000/50000]\n",
      "loss: 0.701064  [41600/50000]\n",
      "loss: 0.764038  [43200/50000]\n",
      "loss: 0.625422  [44800/50000]\n",
      "loss: 0.850141  [46400/50000]\n",
      "loss: 1.374852  [48000/50000]\n",
      "loss: 0.933962  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.063380 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.200477  [    0/50000]\n",
      "loss: 0.693192  [ 1600/50000]\n",
      "loss: 1.222860  [ 3200/50000]\n",
      "loss: 0.864389  [ 4800/50000]\n",
      "loss: 1.166114  [ 6400/50000]\n",
      "loss: 0.935609  [ 8000/50000]\n",
      "loss: 0.812643  [ 9600/50000]\n",
      "loss: 0.646858  [11200/50000]\n",
      "loss: 0.887365  [12800/50000]\n",
      "loss: 1.113470  [14400/50000]\n",
      "loss: 1.064955  [16000/50000]\n",
      "loss: 0.677987  [17600/50000]\n",
      "loss: 1.178486  [19200/50000]\n",
      "loss: 0.424366  [20800/50000]\n",
      "loss: 1.076698  [22400/50000]\n",
      "loss: 0.689292  [24000/50000]\n",
      "loss: 0.835192  [25600/50000]\n",
      "loss: 0.775598  [27200/50000]\n",
      "loss: 0.771842  [28800/50000]\n",
      "loss: 0.622178  [30400/50000]\n",
      "loss: 0.916080  [32000/50000]\n",
      "loss: 0.889935  [33600/50000]\n",
      "loss: 0.798574  [35200/50000]\n",
      "loss: 0.321543  [36800/50000]\n",
      "loss: 0.956259  [38400/50000]\n",
      "loss: 1.286719  [40000/50000]\n",
      "loss: 1.558435  [41600/50000]\n",
      "loss: 0.790356  [43200/50000]\n",
      "loss: 0.641465  [44800/50000]\n",
      "loss: 0.946976  [46400/50000]\n",
      "loss: 0.947768  [48000/50000]\n",
      "loss: 0.919675  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.773028 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.048666  [    0/50000]\n",
      "loss: 0.932098  [ 1600/50000]\n",
      "loss: 0.398541  [ 3200/50000]\n",
      "loss: 0.559541  [ 4800/50000]\n",
      "loss: 0.594011  [ 6400/50000]\n",
      "loss: 0.725540  [ 8000/50000]\n",
      "loss: 0.612898  [ 9600/50000]\n",
      "loss: 0.394320  [11200/50000]\n",
      "loss: 0.466759  [12800/50000]\n",
      "loss: 0.775611  [14400/50000]\n",
      "loss: 0.562654  [16000/50000]\n",
      "loss: 0.860853  [17600/50000]\n",
      "loss: 1.238767  [19200/50000]\n",
      "loss: 0.761498  [20800/50000]\n",
      "loss: 0.758884  [22400/50000]\n",
      "loss: 0.182596  [24000/50000]\n",
      "loss: 0.711875  [25600/50000]\n",
      "loss: 0.459622  [27200/50000]\n",
      "loss: 0.899159  [28800/50000]\n",
      "loss: 0.491664  [30400/50000]\n",
      "loss: 0.369094  [32000/50000]\n",
      "loss: 0.419020  [33600/50000]\n",
      "loss: 0.572690  [35200/50000]\n",
      "loss: 0.281389  [36800/50000]\n",
      "loss: 0.869890  [38400/50000]\n",
      "loss: 0.678378  [40000/50000]\n",
      "loss: 0.867857  [41600/50000]\n",
      "loss: 0.536247  [43200/50000]\n",
      "loss: 0.440229  [44800/50000]\n",
      "loss: 0.524859  [46400/50000]\n",
      "loss: 0.511785  [48000/50000]\n",
      "loss: 0.319569  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.608940 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.564976  [    0/50000]\n",
      "loss: 0.377546  [ 1600/50000]\n",
      "loss: 0.399677  [ 3200/50000]\n",
      "loss: 0.568390  [ 4800/50000]\n",
      "loss: 1.291906  [ 6400/50000]\n",
      "loss: 0.232750  [ 8000/50000]\n",
      "loss: 0.662637  [ 9600/50000]\n",
      "loss: 0.221749  [11200/50000]\n",
      "loss: 0.491909  [12800/50000]\n",
      "loss: 0.228083  [14400/50000]\n",
      "loss: 0.442064  [16000/50000]\n",
      "loss: 0.342851  [17600/50000]\n",
      "loss: 0.305269  [19200/50000]\n",
      "loss: 0.505210  [20800/50000]\n",
      "loss: 0.365105  [22400/50000]\n",
      "loss: 0.644513  [24000/50000]\n",
      "loss: 0.701437  [25600/50000]\n",
      "loss: 0.288216  [27200/50000]\n",
      "loss: 0.724133  [28800/50000]\n",
      "loss: 0.266599  [30400/50000]\n",
      "loss: 0.378182  [32000/50000]\n",
      "loss: 0.620823  [33600/50000]\n",
      "loss: 0.478881  [35200/50000]\n",
      "loss: 0.388927  [36800/50000]\n",
      "loss: 0.162661  [38400/50000]\n",
      "loss: 0.605134  [40000/50000]\n",
      "loss: 0.865529  [41600/50000]\n",
      "loss: 0.282627  [43200/50000]\n",
      "loss: 0.546776  [44800/50000]\n",
      "loss: 0.363260  [46400/50000]\n",
      "loss: 0.523151  [48000/50000]\n",
      "loss: 0.585361  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.540279 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.911598  [    0/50000]\n",
      "loss: 0.765255  [ 1600/50000]\n",
      "loss: 0.581102  [ 3200/50000]\n",
      "loss: 0.108775  [ 4800/50000]\n",
      "loss: 0.318441  [ 6400/50000]\n",
      "loss: 0.225599  [ 8000/50000]\n",
      "loss: 0.457941  [ 9600/50000]\n",
      "loss: 0.465546  [11200/50000]\n",
      "loss: 0.408823  [12800/50000]\n",
      "loss: 0.162762  [14400/50000]\n",
      "loss: 0.610375  [16000/50000]\n",
      "loss: 0.252796  [17600/50000]\n",
      "loss: 0.593448  [19200/50000]\n",
      "loss: 0.226966  [20800/50000]\n",
      "loss: 0.471697  [22400/50000]\n",
      "loss: 0.300750  [24000/50000]\n",
      "loss: 0.833615  [25600/50000]\n",
      "loss: 0.172982  [27200/50000]\n",
      "loss: 1.174073  [28800/50000]\n",
      "loss: 0.290660  [30400/50000]\n",
      "loss: 0.594854  [32000/50000]\n",
      "loss: 0.191918  [33600/50000]\n",
      "loss: 0.058828  [35200/50000]\n",
      "loss: 0.268363  [36800/50000]\n",
      "loss: 0.518997  [38400/50000]\n",
      "loss: 0.192115  [40000/50000]\n",
      "loss: 0.490421  [41600/50000]\n",
      "loss: 0.183343  [43200/50000]\n",
      "loss: 0.099536  [44800/50000]\n",
      "loss: 0.381861  [46400/50000]\n",
      "loss: 0.422987  [48000/50000]\n",
      "loss: 0.572842  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.527449 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.224154  [    0/50000]\n",
      "loss: 0.288883  [ 1600/50000]\n",
      "loss: 0.210155  [ 3200/50000]\n",
      "loss: 0.239978  [ 4800/50000]\n",
      "loss: 0.469955  [ 6400/50000]\n",
      "loss: 0.198788  [ 8000/50000]\n",
      "loss: 0.271411  [ 9600/50000]\n",
      "loss: 0.256225  [11200/50000]\n",
      "loss: 0.145126  [12800/50000]\n",
      "loss: 0.720851  [14400/50000]\n",
      "loss: 0.128393  [16000/50000]\n",
      "loss: 0.255590  [17600/50000]\n",
      "loss: 0.129118  [19200/50000]\n",
      "loss: 0.210627  [20800/50000]\n",
      "loss: 0.504361  [22400/50000]\n",
      "loss: 0.193509  [24000/50000]\n",
      "loss: 0.361788  [25600/50000]\n",
      "loss: 0.091759  [27200/50000]\n",
      "loss: 0.613095  [28800/50000]\n",
      "loss: 0.409143  [30400/50000]\n",
      "loss: 0.232197  [32000/50000]\n",
      "loss: 0.379507  [33600/50000]\n",
      "loss: 0.416805  [35200/50000]\n",
      "loss: 0.610481  [36800/50000]\n",
      "loss: 0.513415  [38400/50000]\n",
      "loss: 0.147304  [40000/50000]\n",
      "loss: 0.502672  [41600/50000]\n",
      "loss: 0.119432  [43200/50000]\n",
      "loss: 0.056952  [44800/50000]\n",
      "loss: 0.091578  [46400/50000]\n",
      "loss: 0.093224  [48000/50000]\n",
      "loss: 0.385673  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.501933 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.080133  [    0/50000]\n",
      "loss: 0.044086  [ 1600/50000]\n",
      "loss: 0.124919  [ 3200/50000]\n",
      "loss: 0.215615  [ 4800/50000]\n",
      "loss: 0.042188  [ 6400/50000]\n",
      "loss: 0.060817  [ 8000/50000]\n",
      "loss: 0.597202  [ 9600/50000]\n",
      "loss: 0.143397  [11200/50000]\n",
      "loss: 0.046048  [12800/50000]\n",
      "loss: 0.050604  [14400/50000]\n",
      "loss: 0.183797  [16000/50000]\n",
      "loss: 0.052321  [17600/50000]\n",
      "loss: 0.196941  [19200/50000]\n",
      "loss: 0.142822  [20800/50000]\n",
      "loss: 0.014397  [22400/50000]\n",
      "loss: 0.245425  [24000/50000]\n",
      "loss: 0.083387  [25600/50000]\n",
      "loss: 0.071595  [27200/50000]\n",
      "loss: 0.066624  [28800/50000]\n",
      "loss: 0.183014  [30400/50000]\n",
      "loss: 0.539319  [32000/50000]\n",
      "loss: 0.392378  [33600/50000]\n",
      "loss: 0.421362  [35200/50000]\n",
      "loss: 0.187024  [36800/50000]\n",
      "loss: 0.208191  [38400/50000]\n",
      "loss: 0.108042  [40000/50000]\n",
      "loss: 0.142326  [41600/50000]\n",
      "loss: 0.051540  [43200/50000]\n",
      "loss: 0.273194  [44800/50000]\n",
      "loss: 0.143185  [46400/50000]\n",
      "loss: 0.217101  [48000/50000]\n",
      "loss: 0.157709  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.526613 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.166163  [    0/50000]\n",
      "loss: 0.052844  [ 1600/50000]\n",
      "loss: 0.083217  [ 3200/50000]\n",
      "loss: 0.070478  [ 4800/50000]\n",
      "loss: 0.231042  [ 6400/50000]\n",
      "loss: 0.136125  [ 8000/50000]\n",
      "loss: 0.105781  [ 9600/50000]\n",
      "loss: 0.094100  [11200/50000]\n",
      "loss: 0.027947  [12800/50000]\n",
      "loss: 0.056811  [14400/50000]\n",
      "loss: 0.431512  [16000/50000]\n",
      "loss: 0.023409  [17600/50000]\n",
      "loss: 0.018759  [19200/50000]\n",
      "loss: 0.437326  [20800/50000]\n",
      "loss: 0.099455  [22400/50000]\n",
      "loss: 0.169442  [24000/50000]\n",
      "loss: 0.063680  [25600/50000]\n",
      "loss: 0.379589  [27200/50000]\n",
      "loss: 0.557797  [28800/50000]\n",
      "loss: 0.354113  [30400/50000]\n",
      "loss: 0.120584  [32000/50000]\n",
      "loss: 0.295293  [33600/50000]\n",
      "loss: 0.133815  [35200/50000]\n",
      "loss: 0.109265  [36800/50000]\n",
      "loss: 0.129464  [38400/50000]\n",
      "loss: 0.054904  [40000/50000]\n",
      "loss: 0.525234  [41600/50000]\n",
      "loss: 0.030366  [43200/50000]\n",
      "loss: 0.249421  [44800/50000]\n",
      "loss: 0.013368  [46400/50000]\n",
      "loss: 0.193954  [48000/50000]\n",
      "loss: 0.144624  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.533853 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.096384  [    0/50000]\n",
      "loss: 0.015486  [ 1600/50000]\n",
      "loss: 0.013762  [ 3200/50000]\n",
      "loss: 0.036246  [ 4800/50000]\n",
      "loss: 0.275982  [ 6400/50000]\n",
      "loss: 0.102472  [ 8000/50000]\n",
      "loss: 0.035251  [ 9600/50000]\n",
      "loss: 0.023254  [11200/50000]\n",
      "loss: 0.207149  [12800/50000]\n",
      "loss: 0.053652  [14400/50000]\n",
      "loss: 0.271273  [16000/50000]\n",
      "loss: 0.025996  [17600/50000]\n",
      "loss: 0.301359  [19200/50000]\n",
      "loss: 0.159795  [20800/50000]\n",
      "loss: 0.017267  [22400/50000]\n",
      "loss: 0.013565  [24000/50000]\n",
      "loss: 0.055212  [25600/50000]\n",
      "loss: 0.051949  [27200/50000]\n",
      "loss: 0.400325  [28800/50000]\n",
      "loss: 0.211158  [30400/50000]\n",
      "loss: 0.368897  [32000/50000]\n",
      "loss: 0.048554  [33600/50000]\n",
      "loss: 0.139307  [35200/50000]\n",
      "loss: 0.060022  [36800/50000]\n",
      "loss: 0.075512  [38400/50000]\n",
      "loss: 0.084637  [40000/50000]\n",
      "loss: 0.039441  [41600/50000]\n",
      "loss: 0.355914  [43200/50000]\n",
      "loss: 0.074085  [44800/50000]\n",
      "loss: 0.025842  [46400/50000]\n",
      "loss: 0.682043  [48000/50000]\n",
      "loss: 0.069140  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.563308 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.269357  [    0/50000]\n",
      "loss: 0.019181  [ 1600/50000]\n",
      "loss: 0.039544  [ 3200/50000]\n",
      "loss: 0.105171  [ 4800/50000]\n",
      "loss: 0.213480  [ 6400/50000]\n",
      "loss: 0.096768  [ 8000/50000]\n",
      "loss: 0.022043  [ 9600/50000]\n",
      "loss: 0.347130  [11200/50000]\n",
      "loss: 0.002005  [12800/50000]\n",
      "loss: 0.165060  [14400/50000]\n",
      "loss: 0.130712  [16000/50000]\n",
      "loss: 0.029721  [17600/50000]\n",
      "loss: 0.230817  [19200/50000]\n",
      "loss: 0.058957  [20800/50000]\n",
      "loss: 0.020454  [22400/50000]\n",
      "loss: 0.050038  [24000/50000]\n",
      "loss: 0.015464  [25600/50000]\n",
      "loss: 0.012502  [27200/50000]\n",
      "loss: 0.023621  [28800/50000]\n",
      "loss: 0.223697  [30400/50000]\n",
      "loss: 0.225617  [32000/50000]\n",
      "loss: 0.050843  [33600/50000]\n",
      "loss: 0.355585  [35200/50000]\n",
      "loss: 0.157624  [36800/50000]\n",
      "loss: 0.003007  [38400/50000]\n",
      "loss: 0.173354  [40000/50000]\n",
      "loss: 0.062607  [41600/50000]\n",
      "loss: 0.056329  [43200/50000]\n",
      "loss: 0.049583  [44800/50000]\n",
      "loss: 0.067133  [46400/50000]\n",
      "loss: 0.070268  [48000/50000]\n",
      "loss: 0.106568  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.628384 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.003145  [    0/50000]\n",
      "loss: 0.157079  [ 1600/50000]\n",
      "loss: 0.006036  [ 3200/50000]\n",
      "loss: 0.036461  [ 4800/50000]\n",
      "loss: 0.103837  [ 6400/50000]\n",
      "loss: 0.002309  [ 8000/50000]\n",
      "loss: 0.015845  [ 9600/50000]\n",
      "loss: 0.267124  [11200/50000]\n",
      "loss: 0.105159  [12800/50000]\n",
      "loss: 0.005419  [14400/50000]\n",
      "loss: 0.010601  [16000/50000]\n",
      "loss: 0.013313  [17600/50000]\n",
      "loss: 0.032158  [19200/50000]\n",
      "loss: 0.002329  [20800/50000]\n",
      "loss: 0.004338  [22400/50000]\n",
      "loss: 0.225939  [24000/50000]\n",
      "loss: 0.087233  [25600/50000]\n",
      "loss: 0.029326  [27200/50000]\n",
      "loss: 0.166404  [28800/50000]\n",
      "loss: 0.314877  [30400/50000]\n",
      "loss: 0.016710  [32000/50000]\n",
      "loss: 0.360142  [33600/50000]\n",
      "loss: 0.134603  [35200/50000]\n",
      "loss: 0.001573  [36800/50000]\n",
      "loss: 0.004212  [38400/50000]\n",
      "loss: 0.176446  [40000/50000]\n",
      "loss: 0.051824  [41600/50000]\n",
      "loss: 0.092536  [43200/50000]\n",
      "loss: 0.042977  [44800/50000]\n",
      "loss: 0.004940  [46400/50000]\n",
      "loss: 0.176840  [48000/50000]\n",
      "loss: 0.065686  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.632649 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.048582  [    0/50000]\n",
      "loss: 0.049495  [ 1600/50000]\n",
      "loss: 0.008134  [ 3200/50000]\n",
      "loss: 0.022409  [ 4800/50000]\n",
      "loss: 0.007686  [ 6400/50000]\n",
      "loss: 0.001922  [ 8000/50000]\n",
      "loss: 0.021223  [ 9600/50000]\n",
      "loss: 0.015317  [11200/50000]\n",
      "loss: 0.004493  [12800/50000]\n",
      "loss: 0.032161  [14400/50000]\n",
      "loss: 0.008300  [16000/50000]\n",
      "loss: 0.004654  [17600/50000]\n",
      "loss: 0.001765  [19200/50000]\n",
      "loss: 0.057857  [20800/50000]\n",
      "loss: 0.001812  [22400/50000]\n",
      "loss: 0.059145  [24000/50000]\n",
      "loss: 0.069382  [25600/50000]\n",
      "loss: 0.040793  [27200/50000]\n",
      "loss: 0.005997  [28800/50000]\n",
      "loss: 0.058416  [30400/50000]\n",
      "loss: 0.059601  [32000/50000]\n",
      "loss: 0.147905  [33600/50000]\n",
      "loss: 0.195837  [35200/50000]\n",
      "loss: 0.175012  [36800/50000]\n",
      "loss: 0.036881  [38400/50000]\n",
      "loss: 0.052628  [40000/50000]\n",
      "loss: 0.009660  [41600/50000]\n",
      "loss: 0.153320  [43200/50000]\n",
      "loss: 0.056060  [44800/50000]\n",
      "loss: 0.042572  [46400/50000]\n",
      "loss: 0.065062  [48000/50000]\n",
      "loss: 0.121822  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.671916 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.032807  [    0/50000]\n",
      "loss: 0.016958  [ 1600/50000]\n",
      "loss: 0.013021  [ 3200/50000]\n",
      "loss: 0.004746  [ 4800/50000]\n",
      "loss: 0.007736  [ 6400/50000]\n",
      "loss: 0.015940  [ 8000/50000]\n",
      "loss: 0.000879  [ 9600/50000]\n",
      "loss: 0.007053  [11200/50000]\n",
      "loss: 0.008764  [12800/50000]\n",
      "loss: 0.022933  [14400/50000]\n",
      "loss: 0.016463  [16000/50000]\n",
      "loss: 0.259125  [17600/50000]\n",
      "loss: 0.007955  [19200/50000]\n",
      "loss: 0.009660  [20800/50000]\n",
      "loss: 0.008266  [22400/50000]\n",
      "loss: 0.007911  [24000/50000]\n",
      "loss: 0.002265  [25600/50000]\n",
      "loss: 0.026568  [27200/50000]\n",
      "loss: 0.249071  [28800/50000]\n",
      "loss: 0.090366  [30400/50000]\n",
      "loss: 0.018400  [32000/50000]\n",
      "loss: 0.000161  [33600/50000]\n",
      "loss: 0.108797  [35200/50000]\n",
      "loss: 0.043695  [36800/50000]\n",
      "loss: 0.222348  [38400/50000]\n",
      "loss: 0.036744  [40000/50000]\n",
      "loss: 0.344176  [41600/50000]\n",
      "loss: 0.037236  [43200/50000]\n",
      "loss: 0.005294  [44800/50000]\n",
      "loss: 0.017725  [46400/50000]\n",
      "loss: 0.078169  [48000/50000]\n",
      "loss: 0.271662  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.657557 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.007957  [    0/50000]\n",
      "loss: 0.023129  [ 1600/50000]\n",
      "loss: 0.000620  [ 3200/50000]\n",
      "loss: 0.013094  [ 4800/50000]\n",
      "loss: 0.017654  [ 6400/50000]\n",
      "loss: 0.001667  [ 8000/50000]\n",
      "loss: 0.002892  [ 9600/50000]\n",
      "loss: 0.004913  [11200/50000]\n",
      "loss: 0.001619  [12800/50000]\n",
      "loss: 0.129214  [14400/50000]\n",
      "loss: 0.395003  [16000/50000]\n",
      "loss: 0.019149  [17600/50000]\n",
      "loss: 0.077911  [19200/50000]\n",
      "loss: 0.023031  [20800/50000]\n",
      "loss: 0.006699  [22400/50000]\n",
      "loss: 0.061049  [24000/50000]\n",
      "loss: 0.015097  [25600/50000]\n",
      "loss: 0.006737  [27200/50000]\n",
      "loss: 0.037805  [28800/50000]\n",
      "loss: 0.010261  [30400/50000]\n",
      "loss: 0.015467  [32000/50000]\n",
      "loss: 0.042448  [33600/50000]\n",
      "loss: 0.067704  [35200/50000]\n",
      "loss: 0.001520  [36800/50000]\n",
      "loss: 0.001921  [38400/50000]\n",
      "loss: 0.036053  [40000/50000]\n",
      "loss: 0.002737  [41600/50000]\n",
      "loss: 0.144448  [43200/50000]\n",
      "loss: 0.018014  [44800/50000]\n",
      "loss: 0.005318  [46400/50000]\n",
      "loss: 0.067350  [48000/50000]\n",
      "loss: 0.035290  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.661673 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.006167  [    0/50000]\n",
      "loss: 0.008057  [ 1600/50000]\n",
      "loss: 0.000069  [ 3200/50000]\n",
      "loss: 0.011506  [ 4800/50000]\n",
      "loss: 0.007146  [ 6400/50000]\n",
      "loss: 0.001258  [ 8000/50000]\n",
      "loss: 0.001420  [ 9600/50000]\n",
      "loss: 0.004360  [11200/50000]\n",
      "loss: 0.235210  [12800/50000]\n",
      "loss: 0.163819  [14400/50000]\n",
      "loss: 0.009442  [16000/50000]\n",
      "loss: 0.053800  [17600/50000]\n",
      "loss: 0.012275  [19200/50000]\n",
      "loss: 0.022170  [20800/50000]\n",
      "loss: 0.348157  [22400/50000]\n",
      "loss: 0.001101  [24000/50000]\n",
      "loss: 0.032235  [25600/50000]\n",
      "loss: 0.027373  [27200/50000]\n",
      "loss: 0.175162  [28800/50000]\n",
      "loss: 0.006276  [30400/50000]\n",
      "loss: 0.004262  [32000/50000]\n",
      "loss: 0.012933  [33600/50000]\n",
      "loss: 0.122839  [35200/50000]\n",
      "loss: 0.001015  [36800/50000]\n",
      "loss: 0.004915  [38400/50000]\n",
      "loss: 0.034384  [40000/50000]\n",
      "loss: 0.103839  [41600/50000]\n",
      "loss: 0.168581  [43200/50000]\n",
      "loss: 0.008978  [44800/50000]\n",
      "loss: 0.001498  [46400/50000]\n",
      "loss: 0.148492  [48000/50000]\n",
      "loss: 0.071956  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.690373 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader5, model3, loss_fn, optimizer)\n",
    "    test_loop(testloader5, model3, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model3, 'model3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is trained in more epochs, we can conclude that using teacher model and distilling the knowledge in a neural network increase the accuracy. May be it takes more time to train with a teacher but the results are more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader7 = DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "testloader7 = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=models.resnet50(pretrained=True)\n",
    "\n",
    "ftrs=model4.fc.in_features\n",
    "model4.fc=nn.Linear(ftrs, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.to(device)\n",
    "next(model4.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size =16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model4.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.382523  [    0/50000]\n",
      "loss: 2.266681  [  800/50000]\n",
      "loss: 2.069983  [ 1600/50000]\n",
      "loss: 1.983108  [ 2400/50000]\n",
      "loss: 1.983583  [ 3200/50000]\n",
      "loss: 1.706721  [ 4000/50000]\n",
      "loss: 1.784302  [ 4800/50000]\n",
      "loss: 1.439089  [ 5600/50000]\n",
      "loss: 1.433651  [ 6400/50000]\n",
      "loss: 1.254860  [ 7200/50000]\n",
      "loss: 1.321148  [ 8000/50000]\n",
      "loss: 1.228954  [ 8800/50000]\n",
      "loss: 1.032186  [ 9600/50000]\n",
      "loss: 1.020627  [10400/50000]\n",
      "loss: 0.741668  [11200/50000]\n",
      "loss: 1.157192  [12000/50000]\n",
      "loss: 0.899214  [12800/50000]\n",
      "loss: 0.689110  [13600/50000]\n",
      "loss: 0.732615  [14400/50000]\n",
      "loss: 0.956569  [15200/50000]\n",
      "loss: 1.176852  [16000/50000]\n",
      "loss: 0.924006  [16800/50000]\n",
      "loss: 0.804347  [17600/50000]\n",
      "loss: 0.592983  [18400/50000]\n",
      "loss: 0.548827  [19200/50000]\n",
      "loss: 0.444268  [20000/50000]\n",
      "loss: 0.436632  [20800/50000]\n",
      "loss: 0.286955  [21600/50000]\n",
      "loss: 0.643605  [22400/50000]\n",
      "loss: 0.214450  [23200/50000]\n",
      "loss: 0.697296  [24000/50000]\n",
      "loss: 0.353383  [24800/50000]\n",
      "loss: 0.672627  [25600/50000]\n",
      "loss: 0.450023  [26400/50000]\n",
      "loss: 0.207980  [27200/50000]\n",
      "loss: 0.382441  [28000/50000]\n",
      "loss: 0.289975  [28800/50000]\n",
      "loss: 0.501325  [29600/50000]\n",
      "loss: 0.285174  [30400/50000]\n",
      "loss: 0.899580  [31200/50000]\n",
      "loss: 0.328124  [32000/50000]\n",
      "loss: 0.438362  [32800/50000]\n",
      "loss: 0.213983  [33600/50000]\n",
      "loss: 0.179838  [34400/50000]\n",
      "loss: 0.829114  [35200/50000]\n",
      "loss: 0.151307  [36000/50000]\n",
      "loss: 0.328742  [36800/50000]\n",
      "loss: 0.509923  [37600/50000]\n",
      "loss: 0.514542  [38400/50000]\n",
      "loss: 0.658660  [39200/50000]\n",
      "loss: 0.108507  [40000/50000]\n",
      "loss: 0.148743  [40800/50000]\n",
      "loss: 0.441123  [41600/50000]\n",
      "loss: 0.474435  [42400/50000]\n",
      "loss: 0.245748  [43200/50000]\n",
      "loss: 0.289955  [44000/50000]\n",
      "loss: 0.235352  [44800/50000]\n",
      "loss: 0.375758  [45600/50000]\n",
      "loss: 0.891583  [46400/50000]\n",
      "loss: 0.355514  [47200/50000]\n",
      "loss: 0.204619  [48000/50000]\n",
      "loss: 0.120770  [48800/50000]\n",
      "loss: 0.402609  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.336421 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.194790  [    0/50000]\n",
      "loss: 0.166576  [  800/50000]\n",
      "loss: 0.216844  [ 1600/50000]\n",
      "loss: 0.733563  [ 2400/50000]\n",
      "loss: 0.151917  [ 3200/50000]\n",
      "loss: 0.417530  [ 4000/50000]\n",
      "loss: 0.297775  [ 4800/50000]\n",
      "loss: 0.190569  [ 5600/50000]\n",
      "loss: 0.250380  [ 6400/50000]\n",
      "loss: 0.122478  [ 7200/50000]\n",
      "loss: 0.325395  [ 8000/50000]\n",
      "loss: 0.359051  [ 8800/50000]\n",
      "loss: 0.182346  [ 9600/50000]\n",
      "loss: 0.176682  [10400/50000]\n",
      "loss: 0.326629  [11200/50000]\n",
      "loss: 0.215847  [12000/50000]\n",
      "loss: 0.542655  [12800/50000]\n",
      "loss: 0.249045  [13600/50000]\n",
      "loss: 0.111796  [14400/50000]\n",
      "loss: 0.676260  [15200/50000]\n",
      "loss: 0.173805  [16000/50000]\n",
      "loss: 0.488751  [16800/50000]\n",
      "loss: 0.212875  [17600/50000]\n",
      "loss: 0.517412  [18400/50000]\n",
      "loss: 0.586737  [19200/50000]\n",
      "loss: 0.296720  [20000/50000]\n",
      "loss: 0.407743  [20800/50000]\n",
      "loss: 0.563302  [21600/50000]\n",
      "loss: 0.273717  [22400/50000]\n",
      "loss: 0.291372  [23200/50000]\n",
      "loss: 0.428303  [24000/50000]\n",
      "loss: 0.435525  [24800/50000]\n",
      "loss: 0.101024  [25600/50000]\n",
      "loss: 0.501135  [26400/50000]\n",
      "loss: 0.353797  [27200/50000]\n",
      "loss: 0.135517  [28000/50000]\n",
      "loss: 0.227213  [28800/50000]\n",
      "loss: 0.102458  [29600/50000]\n",
      "loss: 0.341334  [30400/50000]\n",
      "loss: 0.462588  [31200/50000]\n",
      "loss: 0.229872  [32000/50000]\n",
      "loss: 0.147455  [32800/50000]\n",
      "loss: 0.276743  [33600/50000]\n",
      "loss: 0.076937  [34400/50000]\n",
      "loss: 0.120398  [35200/50000]\n",
      "loss: 0.164864  [36000/50000]\n",
      "loss: 0.086878  [36800/50000]\n",
      "loss: 0.098494  [37600/50000]\n",
      "loss: 0.258439  [38400/50000]\n",
      "loss: 0.111308  [39200/50000]\n",
      "loss: 0.491342  [40000/50000]\n",
      "loss: 0.296585  [40800/50000]\n",
      "loss: 0.146584  [41600/50000]\n",
      "loss: 0.220298  [42400/50000]\n",
      "loss: 0.271525  [43200/50000]\n",
      "loss: 0.200866  [44000/50000]\n",
      "loss: 0.320016  [44800/50000]\n",
      "loss: 0.349045  [45600/50000]\n",
      "loss: 0.571353  [46400/50000]\n",
      "loss: 0.108898  [47200/50000]\n",
      "loss: 0.243809  [48000/50000]\n",
      "loss: 0.317493  [48800/50000]\n",
      "loss: 0.209329  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.248634 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.059201  [    0/50000]\n",
      "loss: 0.306668  [  800/50000]\n",
      "loss: 0.236038  [ 1600/50000]\n",
      "loss: 0.232799  [ 2400/50000]\n",
      "loss: 0.220885  [ 3200/50000]\n",
      "loss: 0.243519  [ 4000/50000]\n",
      "loss: 0.107747  [ 4800/50000]\n",
      "loss: 0.174631  [ 5600/50000]\n",
      "loss: 0.133051  [ 6400/50000]\n",
      "loss: 0.171050  [ 7200/50000]\n",
      "loss: 0.651430  [ 8000/50000]\n",
      "loss: 0.117408  [ 8800/50000]\n",
      "loss: 0.130779  [ 9600/50000]\n",
      "loss: 0.537688  [10400/50000]\n",
      "loss: 0.368844  [11200/50000]\n",
      "loss: 0.106404  [12000/50000]\n",
      "loss: 0.112352  [12800/50000]\n",
      "loss: 0.102217  [13600/50000]\n",
      "loss: 0.085496  [14400/50000]\n",
      "loss: 0.393510  [15200/50000]\n",
      "loss: 0.152718  [16000/50000]\n",
      "loss: 0.320305  [16800/50000]\n",
      "loss: 0.242428  [17600/50000]\n",
      "loss: 0.151637  [18400/50000]\n",
      "loss: 0.057298  [19200/50000]\n",
      "loss: 0.096612  [20000/50000]\n",
      "loss: 0.102053  [20800/50000]\n",
      "loss: 0.329172  [21600/50000]\n",
      "loss: 0.167973  [22400/50000]\n",
      "loss: 0.322765  [23200/50000]\n",
      "loss: 0.061281  [24000/50000]\n",
      "loss: 0.046795  [24800/50000]\n",
      "loss: 0.065866  [25600/50000]\n",
      "loss: 0.061726  [26400/50000]\n",
      "loss: 0.132046  [27200/50000]\n",
      "loss: 0.287357  [28000/50000]\n",
      "loss: 0.045838  [28800/50000]\n",
      "loss: 0.075771  [29600/50000]\n",
      "loss: 0.395473  [30400/50000]\n",
      "loss: 0.262189  [31200/50000]\n",
      "loss: 0.186591  [32000/50000]\n",
      "loss: 0.586030  [32800/50000]\n",
      "loss: 0.106902  [33600/50000]\n",
      "loss: 0.032128  [34400/50000]\n",
      "loss: 0.029786  [35200/50000]\n",
      "loss: 0.389131  [36000/50000]\n",
      "loss: 0.247309  [36800/50000]\n",
      "loss: 0.129532  [37600/50000]\n",
      "loss: 0.120397  [38400/50000]\n",
      "loss: 0.101421  [39200/50000]\n",
      "loss: 0.261546  [40000/50000]\n",
      "loss: 0.058931  [40800/50000]\n",
      "loss: 0.262443  [41600/50000]\n",
      "loss: 0.042464  [42400/50000]\n",
      "loss: 0.060499  [43200/50000]\n",
      "loss: 0.058648  [44000/50000]\n",
      "loss: 0.036768  [44800/50000]\n",
      "loss: 0.161232  [45600/50000]\n",
      "loss: 0.019686  [46400/50000]\n",
      "loss: 0.085606  [47200/50000]\n",
      "loss: 0.043881  [48000/50000]\n",
      "loss: 0.067051  [48800/50000]\n",
      "loss: 0.027012  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.217063 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.172410  [    0/50000]\n",
      "loss: 0.231095  [  800/50000]\n",
      "loss: 0.146250  [ 1600/50000]\n",
      "loss: 0.178906  [ 2400/50000]\n",
      "loss: 0.043110  [ 3200/50000]\n",
      "loss: 0.043714  [ 4000/50000]\n",
      "loss: 0.259765  [ 4800/50000]\n",
      "loss: 0.144062  [ 5600/50000]\n",
      "loss: 0.045188  [ 6400/50000]\n",
      "loss: 0.015437  [ 7200/50000]\n",
      "loss: 0.184702  [ 8000/50000]\n",
      "loss: 0.114894  [ 8800/50000]\n",
      "loss: 0.026698  [ 9600/50000]\n",
      "loss: 0.178806  [10400/50000]\n",
      "loss: 0.031360  [11200/50000]\n",
      "loss: 0.081675  [12000/50000]\n",
      "loss: 0.091234  [12800/50000]\n",
      "loss: 0.369937  [13600/50000]\n",
      "loss: 0.024520  [14400/50000]\n",
      "loss: 0.090615  [15200/50000]\n",
      "loss: 0.323686  [16000/50000]\n",
      "loss: 0.199094  [16800/50000]\n",
      "loss: 0.134442  [17600/50000]\n",
      "loss: 0.231505  [18400/50000]\n",
      "loss: 0.073176  [19200/50000]\n",
      "loss: 0.152291  [20000/50000]\n",
      "loss: 0.022128  [20800/50000]\n",
      "loss: 0.008368  [21600/50000]\n",
      "loss: 0.201259  [22400/50000]\n",
      "loss: 0.080954  [23200/50000]\n",
      "loss: 0.228898  [24000/50000]\n",
      "loss: 0.075458  [24800/50000]\n",
      "loss: 0.054014  [25600/50000]\n",
      "loss: 0.252916  [26400/50000]\n",
      "loss: 0.563063  [27200/50000]\n",
      "loss: 0.451073  [28000/50000]\n",
      "loss: 0.191778  [28800/50000]\n",
      "loss: 0.031814  [29600/50000]\n",
      "loss: 0.104378  [30400/50000]\n",
      "loss: 0.122979  [31200/50000]\n",
      "loss: 0.080020  [32000/50000]\n",
      "loss: 0.129925  [32800/50000]\n",
      "loss: 0.043454  [33600/50000]\n",
      "loss: 0.127526  [34400/50000]\n",
      "loss: 0.197990  [35200/50000]\n",
      "loss: 0.062990  [36000/50000]\n",
      "loss: 0.138666  [36800/50000]\n",
      "loss: 0.055364  [37600/50000]\n",
      "loss: 0.133569  [38400/50000]\n",
      "loss: 0.076453  [39200/50000]\n",
      "loss: 0.237310  [40000/50000]\n",
      "loss: 0.125134  [40800/50000]\n",
      "loss: 0.035191  [41600/50000]\n",
      "loss: 0.028739  [42400/50000]\n",
      "loss: 0.041024  [43200/50000]\n",
      "loss: 0.069137  [44000/50000]\n",
      "loss: 0.104979  [44800/50000]\n",
      "loss: 0.375682  [45600/50000]\n",
      "loss: 0.102667  [46400/50000]\n",
      "loss: 0.063686  [47200/50000]\n",
      "loss: 0.059001  [48000/50000]\n",
      "loss: 0.119010  [48800/50000]\n",
      "loss: 0.165012  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.202615 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.175222  [    0/50000]\n",
      "loss: 0.247975  [  800/50000]\n",
      "loss: 0.042511  [ 1600/50000]\n",
      "loss: 0.162592  [ 2400/50000]\n",
      "loss: 0.039477  [ 3200/50000]\n",
      "loss: 0.173063  [ 4000/50000]\n",
      "loss: 0.024768  [ 4800/50000]\n",
      "loss: 0.113353  [ 5600/50000]\n",
      "loss: 0.011065  [ 6400/50000]\n",
      "loss: 0.149950  [ 7200/50000]\n",
      "loss: 0.054230  [ 8000/50000]\n",
      "loss: 0.106058  [ 8800/50000]\n",
      "loss: 0.051439  [ 9600/50000]\n",
      "loss: 0.094784  [10400/50000]\n",
      "loss: 0.041508  [11200/50000]\n",
      "loss: 0.027269  [12000/50000]\n",
      "loss: 0.066338  [12800/50000]\n",
      "loss: 0.038016  [13600/50000]\n",
      "loss: 0.030182  [14400/50000]\n",
      "loss: 0.133824  [15200/50000]\n",
      "loss: 0.077862  [16000/50000]\n",
      "loss: 0.212360  [16800/50000]\n",
      "loss: 0.028104  [17600/50000]\n",
      "loss: 0.032248  [18400/50000]\n",
      "loss: 0.086686  [19200/50000]\n",
      "loss: 0.044843  [20000/50000]\n",
      "loss: 0.194239  [20800/50000]\n",
      "loss: 0.045727  [21600/50000]\n",
      "loss: 0.103827  [22400/50000]\n",
      "loss: 0.028628  [23200/50000]\n",
      "loss: 0.122031  [24000/50000]\n",
      "loss: 0.163396  [24800/50000]\n",
      "loss: 0.288171  [25600/50000]\n",
      "loss: 0.046527  [26400/50000]\n",
      "loss: 0.045187  [27200/50000]\n",
      "loss: 0.112180  [28000/50000]\n",
      "loss: 0.142868  [28800/50000]\n",
      "loss: 0.051477  [29600/50000]\n",
      "loss: 0.041228  [30400/50000]\n",
      "loss: 0.035379  [31200/50000]\n",
      "loss: 0.025639  [32000/50000]\n",
      "loss: 0.073442  [32800/50000]\n",
      "loss: 0.099879  [33600/50000]\n",
      "loss: 0.074038  [34400/50000]\n",
      "loss: 0.154693  [35200/50000]\n",
      "loss: 0.122935  [36000/50000]\n",
      "loss: 0.017738  [36800/50000]\n",
      "loss: 0.039025  [37600/50000]\n",
      "loss: 0.095236  [38400/50000]\n",
      "loss: 0.035908  [39200/50000]\n",
      "loss: 0.152311  [40000/50000]\n",
      "loss: 0.183247  [40800/50000]\n",
      "loss: 0.073309  [41600/50000]\n",
      "loss: 0.044113  [42400/50000]\n",
      "loss: 0.193724  [43200/50000]\n",
      "loss: 0.043523  [44000/50000]\n",
      "loss: 0.128285  [44800/50000]\n",
      "loss: 0.087558  [45600/50000]\n",
      "loss: 0.083686  [46400/50000]\n",
      "loss: 0.073703  [47200/50000]\n",
      "loss: 0.047719  [48000/50000]\n",
      "loss: 0.114236  [48800/50000]\n",
      "loss: 0.018208  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.194718 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.098251  [    0/50000]\n",
      "loss: 0.055382  [  800/50000]\n",
      "loss: 0.137792  [ 1600/50000]\n",
      "loss: 0.082952  [ 2400/50000]\n",
      "loss: 0.038700  [ 3200/50000]\n",
      "loss: 0.144638  [ 4000/50000]\n",
      "loss: 0.086604  [ 4800/50000]\n",
      "loss: 0.130626  [ 5600/50000]\n",
      "loss: 0.060058  [ 6400/50000]\n",
      "loss: 0.016239  [ 7200/50000]\n",
      "loss: 0.010443  [ 8000/50000]\n",
      "loss: 0.016580  [ 8800/50000]\n",
      "loss: 0.051304  [ 9600/50000]\n",
      "loss: 0.076015  [10400/50000]\n",
      "loss: 0.043506  [11200/50000]\n",
      "loss: 0.181185  [12000/50000]\n",
      "loss: 0.270094  [12800/50000]\n",
      "loss: 0.017006  [13600/50000]\n",
      "loss: 0.034440  [14400/50000]\n",
      "loss: 0.067495  [15200/50000]\n",
      "loss: 0.090782  [16000/50000]\n",
      "loss: 0.310526  [16800/50000]\n",
      "loss: 0.015311  [17600/50000]\n",
      "loss: 0.031349  [18400/50000]\n",
      "loss: 0.009041  [19200/50000]\n",
      "loss: 0.015106  [20000/50000]\n",
      "loss: 0.053501  [20800/50000]\n",
      "loss: 0.070433  [21600/50000]\n",
      "loss: 0.042713  [22400/50000]\n",
      "loss: 0.055907  [23200/50000]\n",
      "loss: 0.026885  [24000/50000]\n",
      "loss: 0.060322  [24800/50000]\n",
      "loss: 0.026804  [25600/50000]\n",
      "loss: 0.055636  [26400/50000]\n",
      "loss: 0.038973  [27200/50000]\n",
      "loss: 0.217809  [28000/50000]\n",
      "loss: 0.049422  [28800/50000]\n",
      "loss: 0.032088  [29600/50000]\n",
      "loss: 0.014555  [30400/50000]\n",
      "loss: 0.044385  [31200/50000]\n",
      "loss: 0.017952  [32000/50000]\n",
      "loss: 0.080907  [32800/50000]\n",
      "loss: 0.016216  [33600/50000]\n",
      "loss: 0.141330  [34400/50000]\n",
      "loss: 0.042028  [35200/50000]\n",
      "loss: 0.083202  [36000/50000]\n",
      "loss: 0.014055  [36800/50000]\n",
      "loss: 0.166506  [37600/50000]\n",
      "loss: 0.033440  [38400/50000]\n",
      "loss: 0.048376  [39200/50000]\n",
      "loss: 0.011892  [40000/50000]\n",
      "loss: 0.033405  [40800/50000]\n",
      "loss: 0.202946  [41600/50000]\n",
      "loss: 0.014923  [42400/50000]\n",
      "loss: 0.095936  [43200/50000]\n",
      "loss: 0.030631  [44000/50000]\n",
      "loss: 0.066760  [44800/50000]\n",
      "loss: 0.040066  [45600/50000]\n",
      "loss: 0.085228  [46400/50000]\n",
      "loss: 0.050091  [47200/50000]\n",
      "loss: 0.159640  [48000/50000]\n",
      "loss: 0.027878  [48800/50000]\n",
      "loss: 0.029551  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.182953 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.058290  [    0/50000]\n",
      "loss: 0.047725  [  800/50000]\n",
      "loss: 0.007443  [ 1600/50000]\n",
      "loss: 0.025422  [ 2400/50000]\n",
      "loss: 0.053014  [ 3200/50000]\n",
      "loss: 0.013980  [ 4000/50000]\n",
      "loss: 0.255338  [ 4800/50000]\n",
      "loss: 0.032952  [ 5600/50000]\n",
      "loss: 0.071081  [ 6400/50000]\n",
      "loss: 0.057417  [ 7200/50000]\n",
      "loss: 0.026043  [ 8000/50000]\n",
      "loss: 0.047637  [ 8800/50000]\n",
      "loss: 0.057614  [ 9600/50000]\n",
      "loss: 0.042007  [10400/50000]\n",
      "loss: 0.033119  [11200/50000]\n",
      "loss: 0.021273  [12000/50000]\n",
      "loss: 0.180119  [12800/50000]\n",
      "loss: 0.075997  [13600/50000]\n",
      "loss: 0.041664  [14400/50000]\n",
      "loss: 0.027506  [15200/50000]\n",
      "loss: 0.112829  [16000/50000]\n",
      "loss: 0.136610  [16800/50000]\n",
      "loss: 0.140265  [17600/50000]\n",
      "loss: 0.081130  [18400/50000]\n",
      "loss: 0.012939  [19200/50000]\n",
      "loss: 0.038394  [20000/50000]\n",
      "loss: 0.027782  [20800/50000]\n",
      "loss: 0.006738  [21600/50000]\n",
      "loss: 0.007769  [22400/50000]\n",
      "loss: 0.013068  [23200/50000]\n",
      "loss: 0.142753  [24000/50000]\n",
      "loss: 0.167305  [24800/50000]\n",
      "loss: 0.017101  [25600/50000]\n",
      "loss: 0.221700  [26400/50000]\n",
      "loss: 0.035418  [27200/50000]\n",
      "loss: 0.002861  [28000/50000]\n",
      "loss: 0.118543  [28800/50000]\n",
      "loss: 0.030426  [29600/50000]\n",
      "loss: 0.281838  [30400/50000]\n",
      "loss: 0.026472  [31200/50000]\n",
      "loss: 0.057919  [32000/50000]\n",
      "loss: 0.271272  [32800/50000]\n",
      "loss: 0.010477  [33600/50000]\n",
      "loss: 0.030760  [34400/50000]\n",
      "loss: 0.025353  [35200/50000]\n",
      "loss: 0.213382  [36000/50000]\n",
      "loss: 0.173176  [36800/50000]\n",
      "loss: 0.034803  [37600/50000]\n",
      "loss: 0.047296  [38400/50000]\n",
      "loss: 0.066614  [39200/50000]\n",
      "loss: 0.007733  [40000/50000]\n",
      "loss: 0.031674  [40800/50000]\n",
      "loss: 0.043607  [41600/50000]\n",
      "loss: 0.055306  [42400/50000]\n",
      "loss: 0.039826  [43200/50000]\n",
      "loss: 0.009592  [44000/50000]\n",
      "loss: 0.034916  [44800/50000]\n",
      "loss: 0.007415  [45600/50000]\n",
      "loss: 0.030853  [46400/50000]\n",
      "loss: 0.008067  [47200/50000]\n",
      "loss: 0.017570  [48000/50000]\n",
      "loss: 0.048192  [48800/50000]\n",
      "loss: 0.105191  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.181972 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.005665  [    0/50000]\n",
      "loss: 0.405184  [  800/50000]\n",
      "loss: 0.014373  [ 1600/50000]\n",
      "loss: 0.012484  [ 2400/50000]\n",
      "loss: 0.164322  [ 3200/50000]\n",
      "loss: 0.005392  [ 4000/50000]\n",
      "loss: 0.042096  [ 4800/50000]\n",
      "loss: 0.091504  [ 5600/50000]\n",
      "loss: 0.049165  [ 6400/50000]\n",
      "loss: 0.007354  [ 7200/50000]\n",
      "loss: 0.009206  [ 8000/50000]\n",
      "loss: 0.010748  [ 8800/50000]\n",
      "loss: 0.015846  [ 9600/50000]\n",
      "loss: 0.044844  [10400/50000]\n",
      "loss: 0.023899  [11200/50000]\n",
      "loss: 0.009516  [12000/50000]\n",
      "loss: 0.014477  [12800/50000]\n",
      "loss: 0.033110  [13600/50000]\n",
      "loss: 0.039969  [14400/50000]\n",
      "loss: 0.064067  [15200/50000]\n",
      "loss: 0.013692  [16000/50000]\n",
      "loss: 0.043401  [16800/50000]\n",
      "loss: 0.010142  [17600/50000]\n",
      "loss: 0.024606  [18400/50000]\n",
      "loss: 0.004178  [19200/50000]\n",
      "loss: 0.051120  [20000/50000]\n",
      "loss: 0.130269  [20800/50000]\n",
      "loss: 0.012788  [21600/50000]\n",
      "loss: 0.046753  [22400/50000]\n",
      "loss: 0.055978  [23200/50000]\n",
      "loss: 0.032344  [24000/50000]\n",
      "loss: 0.033644  [24800/50000]\n",
      "loss: 0.036917  [25600/50000]\n",
      "loss: 0.066424  [26400/50000]\n",
      "loss: 0.003451  [27200/50000]\n",
      "loss: 0.015989  [28000/50000]\n",
      "loss: 0.004556  [28800/50000]\n",
      "loss: 0.007948  [29600/50000]\n",
      "loss: 0.046428  [30400/50000]\n",
      "loss: 0.016779  [31200/50000]\n",
      "loss: 0.018114  [32000/50000]\n",
      "loss: 0.291403  [32800/50000]\n",
      "loss: 0.227557  [33600/50000]\n",
      "loss: 0.199552  [34400/50000]\n",
      "loss: 0.013103  [35200/50000]\n",
      "loss: 0.002830  [36000/50000]\n",
      "loss: 0.084893  [36800/50000]\n",
      "loss: 0.081246  [37600/50000]\n",
      "loss: 0.055408  [38400/50000]\n",
      "loss: 0.114430  [39200/50000]\n",
      "loss: 0.026382  [40000/50000]\n",
      "loss: 0.164640  [40800/50000]\n",
      "loss: 0.014265  [41600/50000]\n",
      "loss: 0.035676  [42400/50000]\n",
      "loss: 0.170215  [43200/50000]\n",
      "loss: 0.011379  [44000/50000]\n",
      "loss: 0.019802  [44800/50000]\n",
      "loss: 0.008655  [45600/50000]\n",
      "loss: 0.006264  [46400/50000]\n",
      "loss: 0.172413  [47200/50000]\n",
      "loss: 0.093096  [48000/50000]\n",
      "loss: 0.034043  [48800/50000]\n",
      "loss: 0.033121  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.182507 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.016127  [    0/50000]\n",
      "loss: 0.006901  [  800/50000]\n",
      "loss: 0.002367  [ 1600/50000]\n",
      "loss: 0.003507  [ 2400/50000]\n",
      "loss: 0.020940  [ 3200/50000]\n",
      "loss: 0.017665  [ 4000/50000]\n",
      "loss: 0.017967  [ 4800/50000]\n",
      "loss: 0.005903  [ 5600/50000]\n",
      "loss: 0.009370  [ 6400/50000]\n",
      "loss: 0.037889  [ 7200/50000]\n",
      "loss: 0.005019  [ 8000/50000]\n",
      "loss: 0.029227  [ 8800/50000]\n",
      "loss: 0.011259  [ 9600/50000]\n",
      "loss: 0.017988  [10400/50000]\n",
      "loss: 0.026685  [11200/50000]\n",
      "loss: 0.010091  [12000/50000]\n",
      "loss: 0.018595  [12800/50000]\n",
      "loss: 0.147794  [13600/50000]\n",
      "loss: 0.012064  [14400/50000]\n",
      "loss: 0.003279  [15200/50000]\n",
      "loss: 0.009696  [16000/50000]\n",
      "loss: 0.038423  [16800/50000]\n",
      "loss: 0.003560  [17600/50000]\n",
      "loss: 0.013674  [18400/50000]\n",
      "loss: 0.051938  [19200/50000]\n",
      "loss: 0.012606  [20000/50000]\n",
      "loss: 0.022398  [20800/50000]\n",
      "loss: 0.084170  [21600/50000]\n",
      "loss: 0.042283  [22400/50000]\n",
      "loss: 0.015109  [23200/50000]\n",
      "loss: 0.010921  [24000/50000]\n",
      "loss: 0.003538  [24800/50000]\n",
      "loss: 0.036788  [25600/50000]\n",
      "loss: 0.045851  [26400/50000]\n",
      "loss: 0.008001  [27200/50000]\n",
      "loss: 0.005014  [28000/50000]\n",
      "loss: 0.031624  [28800/50000]\n",
      "loss: 0.013738  [29600/50000]\n",
      "loss: 0.010509  [30400/50000]\n",
      "loss: 0.027961  [31200/50000]\n",
      "loss: 0.006599  [32000/50000]\n",
      "loss: 0.013069  [32800/50000]\n",
      "loss: 0.025560  [33600/50000]\n",
      "loss: 0.019180  [34400/50000]\n",
      "loss: 0.046388  [35200/50000]\n",
      "loss: 0.020705  [36000/50000]\n",
      "loss: 0.017058  [36800/50000]\n",
      "loss: 0.037953  [37600/50000]\n",
      "loss: 0.117907  [38400/50000]\n",
      "loss: 0.025619  [39200/50000]\n",
      "loss: 0.028357  [40000/50000]\n",
      "loss: 0.011551  [40800/50000]\n",
      "loss: 0.003244  [41600/50000]\n",
      "loss: 0.003340  [42400/50000]\n",
      "loss: 0.012412  [43200/50000]\n",
      "loss: 0.074783  [44000/50000]\n",
      "loss: 0.082636  [44800/50000]\n",
      "loss: 0.168104  [45600/50000]\n",
      "loss: 0.005585  [46400/50000]\n",
      "loss: 0.043739  [47200/50000]\n",
      "loss: 0.043948  [48000/50000]\n",
      "loss: 0.012571  [48800/50000]\n",
      "loss: 0.032475  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.192417 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.010522  [    0/50000]\n",
      "loss: 0.033991  [  800/50000]\n",
      "loss: 0.017423  [ 1600/50000]\n",
      "loss: 0.025488  [ 2400/50000]\n",
      "loss: 0.042125  [ 3200/50000]\n",
      "loss: 0.013035  [ 4000/50000]\n",
      "loss: 0.014516  [ 4800/50000]\n",
      "loss: 0.003283  [ 5600/50000]\n",
      "loss: 0.006038  [ 6400/50000]\n",
      "loss: 0.003824  [ 7200/50000]\n",
      "loss: 0.015654  [ 8000/50000]\n",
      "loss: 0.001879  [ 8800/50000]\n",
      "loss: 0.123683  [ 9600/50000]\n",
      "loss: 0.006152  [10400/50000]\n",
      "loss: 0.003242  [11200/50000]\n",
      "loss: 0.005500  [12000/50000]\n",
      "loss: 0.007570  [12800/50000]\n",
      "loss: 0.041041  [13600/50000]\n",
      "loss: 0.203072  [14400/50000]\n",
      "loss: 0.008199  [15200/50000]\n",
      "loss: 0.055473  [16000/50000]\n",
      "loss: 0.044090  [16800/50000]\n",
      "loss: 0.008036  [17600/50000]\n",
      "loss: 0.009150  [18400/50000]\n",
      "loss: 0.054165  [19200/50000]\n",
      "loss: 0.006315  [20000/50000]\n",
      "loss: 0.009712  [20800/50000]\n",
      "loss: 0.004721  [21600/50000]\n",
      "loss: 0.077105  [22400/50000]\n",
      "loss: 0.008574  [23200/50000]\n",
      "loss: 0.013209  [24000/50000]\n",
      "loss: 0.013277  [24800/50000]\n",
      "loss: 0.007392  [25600/50000]\n",
      "loss: 0.132828  [26400/50000]\n",
      "loss: 0.006835  [27200/50000]\n",
      "loss: 0.109723  [28000/50000]\n",
      "loss: 0.003663  [28800/50000]\n",
      "loss: 0.042041  [29600/50000]\n",
      "loss: 0.019826  [30400/50000]\n",
      "loss: 0.002069  [31200/50000]\n",
      "loss: 0.012899  [32000/50000]\n",
      "loss: 0.020940  [32800/50000]\n",
      "loss: 0.010041  [33600/50000]\n",
      "loss: 0.003078  [34400/50000]\n",
      "loss: 0.023033  [35200/50000]\n",
      "loss: 0.004305  [36000/50000]\n",
      "loss: 0.012323  [36800/50000]\n",
      "loss: 0.006318  [37600/50000]\n",
      "loss: 0.009847  [38400/50000]\n",
      "loss: 0.011053  [39200/50000]\n",
      "loss: 0.006085  [40000/50000]\n",
      "loss: 0.000431  [40800/50000]\n",
      "loss: 0.001582  [41600/50000]\n",
      "loss: 0.028826  [42400/50000]\n",
      "loss: 0.019721  [43200/50000]\n",
      "loss: 0.051883  [44000/50000]\n",
      "loss: 0.011238  [44800/50000]\n",
      "loss: 0.040726  [45600/50000]\n",
      "loss: 0.007287  [46400/50000]\n",
      "loss: 0.012322  [47200/50000]\n",
      "loss: 0.036742  [48000/50000]\n",
      "loss: 0.063101  [48800/50000]\n",
      "loss: 0.042978  [49600/50000]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.183305 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader7, model4, loss_fn, optimizer)\n",
    "    test_loop(testloader7, model4, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4, 'model4.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning has better results. Applying fine-tuning allows us to utilize pre-trained networks to recognize classes they were not originally trained on. And furthermore, this method can lead to higher accuracy than transfer learning via feature extraction. However linear tuning is much faster than fine tuning. Linear tuning acts better when the two datasets of pretrained model and new model are similar and rather small. If datasets are similar but huge, it's better to train more layers of FC part. For different datasets, it's maybe better to use fine tuning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bf51988b82946538e1a85d5b53726fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19a5b7a5ea9c4182bc6fa620a5af6249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce9da50a38e34b868c18973f0cffc933",
       "IPY_MODEL_bad233a0ed64427cb14c230067600293",
       "IPY_MODEL_3350db4ae2b342d28f5ed16ac05abe2d"
      ],
      "layout": "IPY_MODEL_f0d1b4af92034aba9cae30b914f1b1f9"
     }
    },
    "3350db4ae2b342d28f5ed16ac05abe2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44f596b2d8d9451fbd6308f8ea1ce833",
      "placeholder": "",
      "style": "IPY_MODEL_d86d5a04a801430d847dc797bfe33acd",
      "value": " 170498071/170498071 [00:02&lt;00:00, 87251721.43it/s]"
     }
    },
    "44f596b2d8d9451fbd6308f8ea1ce833": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "463fe3a6f44b4509a4bb9b2b0e0e5dbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54a8f3135f1447c0a87409f6927766ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "738e1bec978f48e2af3421f4af0fedfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b32d0c88006a488085e46383811fd58b",
      "max": 102530333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76da5350fea7462ba25bcbca93ec3391",
      "value": 102530333
     }
    },
    "76da5350fea7462ba25bcbca93ec3391": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "987aa9cc9acb4ca7b5660531fb7c67d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a27ee97fe2654b3fb4604b2e4069b384",
       "IPY_MODEL_738e1bec978f48e2af3421f4af0fedfa",
       "IPY_MODEL_d9697cae4ad549f4baad0aa935a9245f"
      ],
      "layout": "IPY_MODEL_0bf51988b82946538e1a85d5b53726fa"
     }
    },
    "99aa764056764b6689c98033b8e6ffd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a27ee97fe2654b3fb4604b2e4069b384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99aa764056764b6689c98033b8e6ffd8",
      "placeholder": "",
      "style": "IPY_MODEL_463fe3a6f44b4509a4bb9b2b0e0e5dbf",
      "value": "100%"
     }
    },
    "aa6dc51798d44580930f20441d04bd16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b32d0c88006a488085e46383811fd58b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8a450688abb424ca6a97be662975900": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bad233a0ed64427cb14c230067600293": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c02e24ee6888472ab421f3f36e2396af",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d22608fe8690420b82ccf121a5583781",
      "value": 170498071
     }
    },
    "c02e24ee6888472ab421f3f36e2396af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce9da50a38e34b868c18973f0cffc933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa6dc51798d44580930f20441d04bd16",
      "placeholder": "",
      "style": "IPY_MODEL_e9e2206572a14068a167b1d34ef50d52",
      "value": "100%"
     }
    },
    "d22608fe8690420b82ccf121a5583781": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d86d5a04a801430d847dc797bfe33acd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9697cae4ad549f4baad0aa935a9245f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54a8f3135f1447c0a87409f6927766ac",
      "placeholder": "",
      "style": "IPY_MODEL_b8a450688abb424ca6a97be662975900",
      "value": " 97.8M/97.8M [00:00&lt;00:00, 139MB/s]"
     }
    },
    "e9e2206572a14068a167b1d34ef50d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0d1b4af92034aba9cae30b914f1b1f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
